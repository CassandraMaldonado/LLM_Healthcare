{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a49d72b6f6624f46b4d1f59c8786a905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76a187c6c9444c108c5bd121c0a49923",
              "IPY_MODEL_9b9f75870bf6463992943d33a3299cff",
              "IPY_MODEL_40d2436004bf49eba58665901671569a"
            ],
            "layout": "IPY_MODEL_a10704c6882648728b76a032a33c36d7"
          }
        },
        "76a187c6c9444c108c5bd121c0a49923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8165fac58fd4a55bf3908869ba3ca7f",
            "placeholder": "​",
            "style": "IPY_MODEL_4fbe2f2f4e9744e7a9f4dfaec90579e1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9b9f75870bf6463992943d33a3299cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2dd629b1246447ab8c7921d076c19cf",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e399cc769844cf4a2b305303c58a637",
            "value": 614
          }
        },
        "40d2436004bf49eba58665901671569a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d243d89f9f14e1ea368863007b51aea",
            "placeholder": "​",
            "style": "IPY_MODEL_17e644ad5b3e47399178005201632a4c",
            "value": " 614/614 [00:00&lt;00:00, 28.7kB/s]"
          }
        },
        "a10704c6882648728b76a032a33c36d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8165fac58fd4a55bf3908869ba3ca7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fbe2f2f4e9744e7a9f4dfaec90579e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2dd629b1246447ab8c7921d076c19cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e399cc769844cf4a2b305303c58a637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d243d89f9f14e1ea368863007b51aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17e644ad5b3e47399178005201632a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1874880399694963a8f09c6c27dd2a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d06f95c844f4a269e8fc7d559d7ceee",
              "IPY_MODEL_6134d7b5b1ea4f15b6e8b956258039ce",
              "IPY_MODEL_25e413bc142b4291ad346f7fca8459bb"
            ],
            "layout": "IPY_MODEL_b5531da737714323a5b40fda13550d99"
          }
        },
        "4d06f95c844f4a269e8fc7d559d7ceee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6724f4d6f3464f9e894d847f3f446f36",
            "placeholder": "​",
            "style": "IPY_MODEL_a20e2b1d58e6409e8e26307cbb429d4b",
            "value": "vocab.json: "
          }
        },
        "6134d7b5b1ea4f15b6e8b956258039ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_172557189be94c03aa7726a4d7dcc670",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d8ea49f180d4f34866d3ab9657a8301",
            "value": 1
          }
        },
        "25e413bc142b4291ad346f7fca8459bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86096e997b3045ffae09663204ecaaf1",
            "placeholder": "​",
            "style": "IPY_MODEL_685215b84f0a48a593fc88ebe30e9895",
            "value": " 1.04M/? [00:00&lt;00:00, 17.8MB/s]"
          }
        },
        "b5531da737714323a5b40fda13550d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6724f4d6f3464f9e894d847f3f446f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a20e2b1d58e6409e8e26307cbb429d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "172557189be94c03aa7726a4d7dcc670": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7d8ea49f180d4f34866d3ab9657a8301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86096e997b3045ffae09663204ecaaf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "685215b84f0a48a593fc88ebe30e9895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77dfc918bf434412967e29ce43176df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f140a1e3cba4cf290e0ecaa27e7c9c7",
              "IPY_MODEL_b7aa97014ec6403390e9bc191fa84f6e",
              "IPY_MODEL_a7e56f1b3153489a9dd00fc8775f7468"
            ],
            "layout": "IPY_MODEL_3bb512728c874a868fcbf7393119b58e"
          }
        },
        "1f140a1e3cba4cf290e0ecaa27e7c9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca3621c83d234f6691d7f0cfcaf32c23",
            "placeholder": "​",
            "style": "IPY_MODEL_9803c815ec0840b081029efb12a4d8e8",
            "value": "merges.txt: "
          }
        },
        "b7aa97014ec6403390e9bc191fa84f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3760a4b315534daabe7bbc2d8f64fc24",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c27ad98326649a99f39bc5c40e5b489",
            "value": 1
          }
        },
        "a7e56f1b3153489a9dd00fc8775f7468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d20f73004b54e4f9e7095a9a97a9684",
            "placeholder": "​",
            "style": "IPY_MODEL_258d2d8c1e854864a334986ac5e46d8d",
            "value": " 456k/? [00:00&lt;00:00, 21.8MB/s]"
          }
        },
        "3bb512728c874a868fcbf7393119b58e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3621c83d234f6691d7f0cfcaf32c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9803c815ec0840b081029efb12a4d8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3760a4b315534daabe7bbc2d8f64fc24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3c27ad98326649a99f39bc5c40e5b489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d20f73004b54e4f9e7095a9a97a9684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258d2d8c1e854864a334986ac5e46d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b80e08784ac944b4980017b65f142f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_553b736e3518459a8da2578baeeac383",
              "IPY_MODEL_c099a8af46714891a44067173954722c",
              "IPY_MODEL_081c2c08bb514fee8fd8d641f8adeb6c"
            ],
            "layout": "IPY_MODEL_3a89faf2430d48b29a9e96cbe78a6211"
          }
        },
        "553b736e3518459a8da2578baeeac383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8102a7683e4d42eb9cfaf7f6b4dfea7a",
            "placeholder": "​",
            "style": "IPY_MODEL_53e7ffa7f44a4eb59ad17ce29b7ad6b2",
            "value": "config.json: 100%"
          }
        },
        "c099a8af46714891a44067173954722c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a82a854f7f134529b7e8d4c38d0ac697",
            "max": 641,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0228be5424647199645ed1a9ec03fc0",
            "value": 641
          }
        },
        "081c2c08bb514fee8fd8d641f8adeb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de0bef67cd04158ac67373ff1565f5a",
            "placeholder": "​",
            "style": "IPY_MODEL_8501c1adce1d432f9ec1dd71344a8e27",
            "value": " 641/641 [00:00&lt;00:00, 48.4kB/s]"
          }
        },
        "3a89faf2430d48b29a9e96cbe78a6211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8102a7683e4d42eb9cfaf7f6b4dfea7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e7ffa7f44a4eb59ad17ce29b7ad6b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a82a854f7f134529b7e8d4c38d0ac697": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0228be5424647199645ed1a9ec03fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5de0bef67cd04158ac67373ff1565f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8501c1adce1d432f9ec1dd71344a8e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c849802170414b68af6929dacea9597c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b56f97f24b8e4d10be5611944fbe37e9",
              "IPY_MODEL_d0d7489acb20480cb7733bb95d4fc6f8",
              "IPY_MODEL_9e0ad3c055974f23a7b14456107bf31b"
            ],
            "layout": "IPY_MODEL_a91222f8845e490fbd43ad1614781e93"
          }
        },
        "b56f97f24b8e4d10be5611944fbe37e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f0bf3afe0e04d5c80df4dbab22ac783",
            "placeholder": "​",
            "style": "IPY_MODEL_54927d38487747d18d1a28ee6c2b50bb",
            "value": "model.safetensors: 100%"
          }
        },
        "d0d7489acb20480cb7733bb95d4fc6f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b1a0a4424c34b50afbc962b3b89f4ec",
            "max": 351256598,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77b6a6b3aab34c3e9f5202322537354f",
            "value": 351256598
          }
        },
        "9e0ad3c055974f23a7b14456107bf31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_446951adfa3e48ebb6995b7e885e6ba2",
            "placeholder": "​",
            "style": "IPY_MODEL_cc22da3c8b7340bda8f5b9d511776c64",
            "value": " 351M/351M [00:02&lt;00:00, 175MB/s]"
          }
        },
        "a91222f8845e490fbd43ad1614781e93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f0bf3afe0e04d5c80df4dbab22ac783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54927d38487747d18d1a28ee6c2b50bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b1a0a4424c34b50afbc962b3b89f4ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77b6a6b3aab34c3e9f5202322537354f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "446951adfa3e48ebb6995b7e885e6ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc22da3c8b7340bda8f5b9d511776c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a42d97f291ca43a7981cf201eca30ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b248c60b3b64fecaabc0d7f0454a4ca",
              "IPY_MODEL_64a50bbefaa744d2b9cfbed51ce8b70b",
              "IPY_MODEL_f998b47ded5f435db4d5b0e171c3715d"
            ],
            "layout": "IPY_MODEL_84f71775ed0243f69b0171a4566444a8"
          }
        },
        "2b248c60b3b64fecaabc0d7f0454a4ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec4044ef4ee4fe994547554d3a7d719",
            "placeholder": "​",
            "style": "IPY_MODEL_1d78ee099cf94c6f96fb104fee07c108",
            "value": "generation_config.json: 100%"
          }
        },
        "64a50bbefaa744d2b9cfbed51ce8b70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26d1ae9d816d4cbd942a4247889ab884",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01482fc424ef4e7ebf54b5323fc0330d",
            "value": 124
          }
        },
        "f998b47ded5f435db4d5b0e171c3715d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be1b54c36a3e4424a3fd4242de5b3be2",
            "placeholder": "​",
            "style": "IPY_MODEL_cc109855d3ba4dc3ba8c124388767f0f",
            "value": " 124/124 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "84f71775ed0243f69b0171a4566444a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec4044ef4ee4fe994547554d3a7d719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d78ee099cf94c6f96fb104fee07c108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26d1ae9d816d4cbd942a4247889ab884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01482fc424ef4e7ebf54b5323fc0330d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be1b54c36a3e4424a3fd4242de5b3be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc109855d3ba4dc3ba8c124388767f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "326c029285f147e6add83e855cf9e149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fa9b0ea266e42c59292dc15a1a837d1",
              "IPY_MODEL_52562666994549899c81ea19487c820e",
              "IPY_MODEL_eed9c053f41448b5bb03a28a081f08b9"
            ],
            "layout": "IPY_MODEL_67fd7cfee5844b81ac9b52616bb51b8b"
          }
        },
        "0fa9b0ea266e42c59292dc15a1a837d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3374a8458ae49df9330350e74324571",
            "placeholder": "​",
            "style": "IPY_MODEL_3ace571a29ec493a890e59974660b0d3",
            "value": "Formatting training data: 100%"
          }
        },
        "52562666994549899c81ea19487c820e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c80e7303f1d4ac3999cf57962e85f35",
            "max": 1800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a11f362526e4ae5a2e0bc7c911adcc4",
            "value": 1800
          }
        },
        "eed9c053f41448b5bb03a28a081f08b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f55df88f20d43c495ea82a9e147588d",
            "placeholder": "​",
            "style": "IPY_MODEL_55b991be4a8f426da61233b7a4ef0090",
            "value": " 1800/1800 [00:00&lt;00:00, 10235.83 examples/s]"
          }
        },
        "67fd7cfee5844b81ac9b52616bb51b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3374a8458ae49df9330350e74324571": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ace571a29ec493a890e59974660b0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c80e7303f1d4ac3999cf57962e85f35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a11f362526e4ae5a2e0bc7c911adcc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f55df88f20d43c495ea82a9e147588d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55b991be4a8f426da61233b7a4ef0090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac07ab8ca3e94501ab5d5fd20345dad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c143a8574ff4ebbbf55b355d50b234f",
              "IPY_MODEL_6b2a885aaf7d4e14a1a35473625657ae",
              "IPY_MODEL_69967f24e4404ff798ea8e4fd4ca14c9"
            ],
            "layout": "IPY_MODEL_9e5a938af37c426e9abaaea4e1864a5d"
          }
        },
        "6c143a8574ff4ebbbf55b355d50b234f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_077c3866cbdf4bd8a015ebce1cc55fd1",
            "placeholder": "​",
            "style": "IPY_MODEL_3f7e2f4149d14ebc93269c26736083d3",
            "value": "Formatting evaluation data: 100%"
          }
        },
        "6b2a885aaf7d4e14a1a35473625657ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_584995b58a8b413f9b0b498e285e35ab",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_649e02b543b14dce917767e43ea1973b",
            "value": 200
          }
        },
        "69967f24e4404ff798ea8e4fd4ca14c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f28cc5cb301c47859cfedb09b046b884",
            "placeholder": "​",
            "style": "IPY_MODEL_70d97091e38c4d9a9a702cb63367b8e9",
            "value": " 200/200 [00:00&lt;00:00, 4954.94 examples/s]"
          }
        },
        "9e5a938af37c426e9abaaea4e1864a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "077c3866cbdf4bd8a015ebce1cc55fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f7e2f4149d14ebc93269c26736083d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "584995b58a8b413f9b0b498e285e35ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "649e02b543b14dce917767e43ea1973b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f28cc5cb301c47859cfedb09b046b884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70d97091e38c4d9a9a702cb63367b8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4cba041729e4fc098b9df4faffdba42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a90b5d1e9f0148018033ed16edc29ec2",
              "IPY_MODEL_12c7d30e1a24457baada1725818a9589",
              "IPY_MODEL_bafb882ed42b4a0b98b8d5bb088003bf"
            ],
            "layout": "IPY_MODEL_a20616e487494b108cc5a4973a026595"
          }
        },
        "a90b5d1e9f0148018033ed16edc29ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21b053311ac94f12bbb35957c8a2d8f8",
            "placeholder": "​",
            "style": "IPY_MODEL_46bb312e1df04418b46dc18419a8a35a",
            "value": "Tokenizing training data: 100%"
          }
        },
        "12c7d30e1a24457baada1725818a9589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48919858e280403aa515cc6d4ed416cb",
            "max": 1800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e1e665dc7bd4e6c91d09d8e43ec2b75",
            "value": 1800
          }
        },
        "bafb882ed42b4a0b98b8d5bb088003bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58b4134bc5404bb2988d1bc2b5dec838",
            "placeholder": "​",
            "style": "IPY_MODEL_50c70fff80384dc08502747dea0b54e0",
            "value": " 1800/1800 [00:07&lt;00:00, 284.98 examples/s]"
          }
        },
        "a20616e487494b108cc5a4973a026595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21b053311ac94f12bbb35957c8a2d8f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46bb312e1df04418b46dc18419a8a35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48919858e280403aa515cc6d4ed416cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e1e665dc7bd4e6c91d09d8e43ec2b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58b4134bc5404bb2988d1bc2b5dec838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50c70fff80384dc08502747dea0b54e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee7b555486ba4b76b56df13aef5f5df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97c1bc2bfd2647b985f15b09655b986a",
              "IPY_MODEL_e744d0335dfb488487dc6cd8f507ea72",
              "IPY_MODEL_a83d3e6b2c3c4fe39391b18f95adfabf"
            ],
            "layout": "IPY_MODEL_f27b3f3823924a2c87d6a1fc5305e2f4"
          }
        },
        "97c1bc2bfd2647b985f15b09655b986a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da23283687ae4395afb27eb241d74d8d",
            "placeholder": "​",
            "style": "IPY_MODEL_df808a49c0df4aafa46a4d5da9fcf04a",
            "value": "Tokenizing evaluation data: 100%"
          }
        },
        "e744d0335dfb488487dc6cd8f507ea72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2372aaa88924a6d8553229368d7dd7d",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c838cfeaee2473cb949352ee5daf9d0",
            "value": 200
          }
        },
        "a83d3e6b2c3c4fe39391b18f95adfabf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe0b06b4d08640089b8cfff1a6703e1a",
            "placeholder": "​",
            "style": "IPY_MODEL_8b55ecca52d1419abe3ed750c0ded29f",
            "value": " 200/200 [00:00&lt;00:00, 242.87 examples/s]"
          }
        },
        "f27b3f3823924a2c87d6a1fc5305e2f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da23283687ae4395afb27eb241d74d8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df808a49c0df4aafa46a4d5da9fcf04a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2372aaa88924a6d8553229368d7dd7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c838cfeaee2473cb949352ee5daf9d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe0b06b4d08640089b8cfff1a6703e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b55ecca52d1419abe3ed750c0ded29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# %pip install trl\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_requirements():\n",
        "    packages = [\n",
        "        \"bitsandbytes\",\n",
        "        \"accelerate\",\n",
        "        \"peft\",\n",
        "        \"trl\",\n",
        "        \"datasets\",\n",
        "        \"transformers\",\n",
        "        \"torch\",\n",
        "        \"wandb\",\n",
        "        \"scikit-learn\"\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        try:\n",
        "            __import__(package)\n",
        "            print(f\"{package} already installed.\")\n",
        "        except ImportError:\n",
        "            print(f\"Installing {package}.\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "            print(f\"{package} installed successfully.\")\n",
        "\n",
        "install_requirements()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGIlIWGucoVZ",
        "outputId": "3ad298c2-48ac-4a19-e951-0e544b717dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing bitsandbytes.\n",
            "bitsandbytes installed successfully.\n",
            "accelerate already installed.\n",
            "peft already installed.\n",
            "Installing trl.\n",
            "trl installed successfully.\n",
            "datasets already installed.\n",
            "transformers already installed.\n",
            "torch already installed.\n",
            "wandb already installed.\n",
            "Installing scikit-learn.\n",
            "scikit-learn installed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import torch\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Optional, Any\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import math\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    EarlyStoppingCallback,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    TaskType,\n",
        "    prepare_model_for_kbit_training,\n",
        "    PeftModel\n",
        ")\n",
        "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
        "from datasets import Dataset, DatasetDict\n",
        "import wandb\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "HyOQuitVcvHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "RbJRciAQcw1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a49d72b6f6624f46b4d1f59c8786a905",
            "76a187c6c9444c108c5bd121c0a49923",
            "9b9f75870bf6463992943d33a3299cff",
            "40d2436004bf49eba58665901671569a",
            "a10704c6882648728b76a032a33c36d7",
            "b8165fac58fd4a55bf3908869ba3ca7f",
            "4fbe2f2f4e9744e7a9f4dfaec90579e1",
            "c2dd629b1246447ab8c7921d076c19cf",
            "4e399cc769844cf4a2b305303c58a637",
            "2d243d89f9f14e1ea368863007b51aea",
            "17e644ad5b3e47399178005201632a4c",
            "1874880399694963a8f09c6c27dd2a8e",
            "4d06f95c844f4a269e8fc7d559d7ceee",
            "6134d7b5b1ea4f15b6e8b956258039ce",
            "25e413bc142b4291ad346f7fca8459bb",
            "b5531da737714323a5b40fda13550d99",
            "6724f4d6f3464f9e894d847f3f446f36",
            "a20e2b1d58e6409e8e26307cbb429d4b",
            "172557189be94c03aa7726a4d7dcc670",
            "7d8ea49f180d4f34866d3ab9657a8301",
            "86096e997b3045ffae09663204ecaaf1",
            "685215b84f0a48a593fc88ebe30e9895",
            "77dfc918bf434412967e29ce43176df7",
            "1f140a1e3cba4cf290e0ecaa27e7c9c7",
            "b7aa97014ec6403390e9bc191fa84f6e",
            "a7e56f1b3153489a9dd00fc8775f7468",
            "3bb512728c874a868fcbf7393119b58e",
            "ca3621c83d234f6691d7f0cfcaf32c23",
            "9803c815ec0840b081029efb12a4d8e8",
            "3760a4b315534daabe7bbc2d8f64fc24",
            "3c27ad98326649a99f39bc5c40e5b489",
            "8d20f73004b54e4f9e7095a9a97a9684",
            "258d2d8c1e854864a334986ac5e46d8d",
            "b80e08784ac944b4980017b65f142f37",
            "553b736e3518459a8da2578baeeac383",
            "c099a8af46714891a44067173954722c",
            "081c2c08bb514fee8fd8d641f8adeb6c",
            "3a89faf2430d48b29a9e96cbe78a6211",
            "8102a7683e4d42eb9cfaf7f6b4dfea7a",
            "53e7ffa7f44a4eb59ad17ce29b7ad6b2",
            "a82a854f7f134529b7e8d4c38d0ac697",
            "b0228be5424647199645ed1a9ec03fc0",
            "5de0bef67cd04158ac67373ff1565f5a",
            "8501c1adce1d432f9ec1dd71344a8e27",
            "c849802170414b68af6929dacea9597c",
            "b56f97f24b8e4d10be5611944fbe37e9",
            "d0d7489acb20480cb7733bb95d4fc6f8",
            "9e0ad3c055974f23a7b14456107bf31b",
            "a91222f8845e490fbd43ad1614781e93",
            "4f0bf3afe0e04d5c80df4dbab22ac783",
            "54927d38487747d18d1a28ee6c2b50bb",
            "5b1a0a4424c34b50afbc962b3b89f4ec",
            "77b6a6b3aab34c3e9f5202322537354f",
            "446951adfa3e48ebb6995b7e885e6ba2",
            "cc22da3c8b7340bda8f5b9d511776c64",
            "a42d97f291ca43a7981cf201eca30ff5",
            "2b248c60b3b64fecaabc0d7f0454a4ca",
            "64a50bbefaa744d2b9cfbed51ce8b70b",
            "f998b47ded5f435db4d5b0e171c3715d",
            "84f71775ed0243f69b0171a4566444a8",
            "dec4044ef4ee4fe994547554d3a7d719",
            "1d78ee099cf94c6f96fb104fee07c108",
            "26d1ae9d816d4cbd942a4247889ab884",
            "01482fc424ef4e7ebf54b5323fc0330d",
            "be1b54c36a3e4424a3fd4242de5b3be2",
            "cc109855d3ba4dc3ba8c124388767f0f",
            "326c029285f147e6add83e855cf9e149",
            "0fa9b0ea266e42c59292dc15a1a837d1",
            "52562666994549899c81ea19487c820e",
            "eed9c053f41448b5bb03a28a081f08b9",
            "67fd7cfee5844b81ac9b52616bb51b8b",
            "d3374a8458ae49df9330350e74324571",
            "3ace571a29ec493a890e59974660b0d3",
            "0c80e7303f1d4ac3999cf57962e85f35",
            "2a11f362526e4ae5a2e0bc7c911adcc4",
            "1f55df88f20d43c495ea82a9e147588d",
            "55b991be4a8f426da61233b7a4ef0090",
            "ac07ab8ca3e94501ab5d5fd20345dad0",
            "6c143a8574ff4ebbbf55b355d50b234f",
            "6b2a885aaf7d4e14a1a35473625657ae",
            "69967f24e4404ff798ea8e4fd4ca14c9",
            "9e5a938af37c426e9abaaea4e1864a5d",
            "077c3866cbdf4bd8a015ebce1cc55fd1",
            "3f7e2f4149d14ebc93269c26736083d3",
            "584995b58a8b413f9b0b498e285e35ab",
            "649e02b543b14dce917767e43ea1973b",
            "f28cc5cb301c47859cfedb09b046b884",
            "70d97091e38c4d9a9a702cb63367b8e9",
            "f4cba041729e4fc098b9df4faffdba42",
            "a90b5d1e9f0148018033ed16edc29ec2",
            "12c7d30e1a24457baada1725818a9589",
            "bafb882ed42b4a0b98b8d5bb088003bf",
            "a20616e487494b108cc5a4973a026595",
            "21b053311ac94f12bbb35957c8a2d8f8",
            "46bb312e1df04418b46dc18419a8a35a",
            "48919858e280403aa515cc6d4ed416cb",
            "8e1e665dc7bd4e6c91d09d8e43ec2b75",
            "58b4134bc5404bb2988d1bc2b5dec838",
            "50c70fff80384dc08502747dea0b54e0",
            "ee7b555486ba4b76b56df13aef5f5df7",
            "97c1bc2bfd2647b985f15b09655b986a",
            "e744d0335dfb488487dc6cd8f507ea72",
            "a83d3e6b2c3c4fe39391b18f95adfabf",
            "f27b3f3823924a2c87d6a1fc5305e2f4",
            "da23283687ae4395afb27eb241d74d8d",
            "df808a49c0df4aafa46a4d5da9fcf04a",
            "c2372aaa88924a6d8553229368d7dd7d",
            "5c838cfeaee2473cb949352ee5daf9d0",
            "fe0b06b4d08640089b8cfff1a6703e1a",
            "8b55ecca52d1419abe3ed750c0ded29f"
          ]
        },
        "id": "uRZZ-SJabOvu",
        "outputId": "f731393c-9560-42aa-d132-98e6e19cc7a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning loaded.\n",
            "\n",
            "============================================================\n",
            "Multiple ways to upload the file:\n",
            "============================================================\n",
            "\n",
            " Basic:\n",
            "   start_training_basic_mode()\n",
            " Uses standard Trainer and works with any TRL version.\n",
            "\n",
            " Small model mode:\n",
            "   start_training_small_model()\n",
            "DialoGPT-small with adaptive LoRA.\n",
            "\n",
            " Upload file:\n",
            "   start_training_with_upload()\n",
            "Adapts to any model with smart error handling.\n",
            "\n",
            " CPU-only mode:\n",
            "   start_training_cpu_mode()\n",
            " No GPU/quantization, works on any hardware.\n",
            "\n",
            "============================================================\n",
            "Quick Fix for SFTTrainer error:\n",
            "   The trainer now falls back to standard Trainer.\n",
            "   Try: start_training_basic_mode()\n",
            "============================================================\n",
            "\n",
            " Trainer compatability features:\n",
            "- Auto-detects SFTTrainer vs standard Trainer compatibility.\n",
            "- Falls back gracefully if SFTTrainer parameters don't match.\n",
            "- Works with any version of transformers/TRL.\n",
            "- Handles data collator compatibility issues.\n",
            "- Maximum compatibility mode available.\n",
            "Starting with smaller model.\n",
            "Starting Medical Chatbot Fine-tuning Process.\n",
            "============================================================\n",
            "File Upload method.\n",
            "Please select your training file to upload:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-086ce8d2-7ae6-4301-ac2e-d31ba59c6605\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-086ce8d2-7ae6-4301-ac2e-d31ba59c6605\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train_with_cot_radqa.json to train_with_cot_radqa.json\n",
            "Uploaded and saved: train_with_cot_radqa.json\n",
            "Training file: train_with_cot_radqa.json\n",
            "No evaluation file provided, we will split training data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a49d72b6f6624f46b4d1f59c8786a905"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1874880399694963a8f09c6c27dd2a8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77dfc918bf434412967e29ce43176df7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected GPU memory: 14.7 GB\n",
            "Using device map: auto\n",
            "Using quantization: True\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/641 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b80e08784ac944b4980017b65f142f37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/351M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c849802170414b68af6929dacea9597c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Failed to load model with flash attention: FlashAttention2 has been toggled on, but it cannot be used due to the following error: the package flash_attn seems to be not installed. Please refer to the documentation of https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2 to install Flash Attention 2.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a42d97f291ca43a7981cf201eca30ff5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available modules in model: ['wte', 'c_attn', 'c_proj', 'wpe', 'c_fc']\n",
            "Using target modules: ['c_attn', 'c_proj', 'c_fc']\n",
            "trainable params: 1,179,648 || all params: 125,619,456 || trainable%: 0.9391\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Formatting training data:   0%|          | 0/1800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "326c029285f147e6add83e855cf9e149"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Formatting evaluation data:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac07ab8ca3e94501ab5d5fd20345dad0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing training data:   0%|          | 0/1800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4cba041729e4fc098b9df4faffdba42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing evaluation data:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee7b555486ba4b76b56df13aef5f5df7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:SFTTrainer failed: SFTTrainer.__init__() got an unexpected keyword argument 'dataset_text_field'\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  11/3600 00:01 < 11:12, 5.34 it/s, Epoch 0.01/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='99' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 99/100 00:11 < 00:00, 8.82 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Training failed: CUDA out of memory. Tried to allocate 4.79 GiB. GPU 0 has a total capacity of 14.74 GiB of which 4.79 GiB is free. Process 4219 has 9.95 GiB memory in use. Of the allocated memory 5.03 GiB is allocated by PyTorch, and 4.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 4.79 GiB. GPU 0 has a total capacity of 14.74 GiB of which 4.79 GiB is free. Process 4219 has 9.95 GiB memory in use. Of the allocated memory 5.03 GiB is allocated by PyTorch, and 4.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-2945457762.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"- Maximum compatibility mode available.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m \u001b[0mstart_training_small_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;31m# Loading the fine-tuned model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4-2945457762.py\u001b[0m in \u001b[0;36mstart_training_small_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting with smaller model.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m     train_result, eval_metrics = run_training(\n\u001b[0m\u001b[1;32m    941\u001b[0m         \u001b[0mfile_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upload\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"microsoft/DialoGPT-small\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Smaller model for memory efficiency.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4-2945457762.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(file_method, train_file_drive_path, eval_file_drive_path, output_dir, model_name, use_4bit, use_8bit, lora_r, lora_alpha, lora_dropout, epochs, batch_size, learning_rate, eval_steps, save_steps, max_seq_length, use_cot, wandb_project, run_name)\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;31m# Start training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m         train_result, eval_metrics = trainer.train(\n\u001b[0m\u001b[1;32m    875\u001b[0m             \u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0meval_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4-2945457762.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_file, eval_file, output_dir)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# Start training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving final model.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2204\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2206\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2207\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2621\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msteps_skipped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msteps_in_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m                         self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2624\u001b[0m                             \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m                             \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3094\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3096\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3097\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3044\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3045\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3046\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4198\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4199\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4200\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4201\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4419\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4420\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_eval_metrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4421\u001b[0;31m                     \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4422\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4423\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_nested_concat\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_nested_concat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         return type(tensors)(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Let's figure out the new shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.79 GiB. GPU 0 has a total capacity of 14.74 GiB of which 4.79 GiB is free. Process 4219 has 9.95 GiB memory in use. Of the allocated memory 5.03 GiB is allocated by PyTorch, and 4.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class ModelConfig:\n",
        "    model_name: str = \"skumar9/Llama-medx_v3.2\"\n",
        "    use_4bit: bool = True\n",
        "    use_8bit: bool = False\n",
        "    bnb_4bit_compute_dtype: str = \"float16\"\n",
        "    bnb_4bit_quant_type: str = \"nf4\"\n",
        "    use_nested_quant: bool = False\n",
        "    device_map: str = \"auto\"\n",
        "    max_memory: Optional[Dict] = None\n",
        "    torch_dtype: str = \"auto\"\n",
        "    low_cpu_mem_usage: bool = True\n",
        "\n",
        "# Lora fine-tuning.\n",
        "@dataclass\n",
        "class LoRAConfig:\n",
        "    lora_r: int = 64\n",
        "    lora_alpha: int = 16\n",
        "    lora_dropout: float = 0.1\n",
        "    bias: str = \"none\"\n",
        "    task_type: str = \"CAUSAL_LM\"\n",
        "    target_modules: List[str] = field(default_factory=lambda: [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "    ])\n",
        "    inference_mode: bool = False\n",
        "\n",
        "# Training the hyperparameters.\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    num_train_epochs: int = 3\n",
        "    per_device_train_batch_size: int = 2\n",
        "    per_device_eval_batch_size: int = 2\n",
        "    gradient_accumulation_steps: int = 1\n",
        "    learning_rate: float = 2e-5\n",
        "    weight_decay: float = 0.01\n",
        "    lr_scheduler_type: str = \"cosine\"\n",
        "    warmup_ratio: float = 0.03\n",
        "    max_steps: int = -1\n",
        "    eval_steps: int = 100\n",
        "    save_steps: int = 1 # mkly\n",
        "    logging_steps: int = 10\n",
        "    evaluation_strategy: str = \"steps\"\n",
        "    save_strategy: str = \"steps\"\n",
        "    load_best_model_at_end: bool = True\n",
        "    metric_for_best_model: str = \"eval_loss\"\n",
        "    greater_is_better: bool = False\n",
        "    report_to: List[str] = field(default_factory=lambda: [\"tensorboard\"])\n",
        "    dataloader_num_workers: int = 0  # Reduced it to avoid multiprocessing issues.\n",
        "    fp16: bool = True\n",
        "    bf16: bool = False\n",
        "    max_grad_norm: float = 1.0\n",
        "    seed: int = 42\n",
        "    data_seed: int = 42\n",
        "\n",
        "# Data processing.\n",
        "@dataclass\n",
        "class DataConfig:\n",
        "    max_seq_length: int = 2048\n",
        "    instruction_template: str = \"### Human: {instruction}\\n### Assistant:\"\n",
        "    response_template: str = \" {output}\"\n",
        "    cot_template: str = \"\\n\\nThinking step by step:\\n{cot_reasoning}\\n\\nTherefore, \"\n",
        "    use_cot: bool = True\n",
        "    pack_sequences: bool = False\n",
        "    remove_unused_columns: bool = False\n",
        "\n",
        "# For processing the medical data and preparing it.\n",
        "class MedicalDataProcessor:\n",
        "\n",
        "    def __init__(self, config: DataConfig, tokenizer):\n",
        "        self.config = config\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        # Setting up tokenizer special tokens.\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
        "\n",
        "        # Setting padding side for consistency.\n",
        "        self.tokenizer.padding_side = \"right\"\n",
        "\n",
        "    # Tokenizing one sample at a time.\n",
        "    def tokenize_sample(self, sample: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        text = sample[\"text\"]\n",
        "\n",
        "        # Tokenizing the text with padding and truncation. Padding to max_length for consistent tensor sizes and returns a simple dict instead of tensors.\n",
        "        tokenized = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.config.max_seq_length,\n",
        "            return_tensors=None\n",
        "        )\n",
        "\n",
        "        # For causal LM, labels are the same as input ids except for the padding tokens.\n",
        "        labels = tokenized[\"input_ids\"].copy()\n",
        "\n",
        "        # For padding tokens to ignore them in loss calculation.\n",
        "        if \"attention_mask\" in tokenized:\n",
        "            for i, mask in enumerate(tokenized[\"attention_mask\"]):\n",
        "                if mask == 0:\n",
        "                    labels[i] = -100\n",
        "\n",
        "        tokenized[\"labels\"] = labels\n",
        "\n",
        "        return tokenized\n",
        "\n",
        "    def load_dataset(self, train_file: str, eval_file: Optional[str] = None) -> DatasetDict:\n",
        "        logger.info(f\"Loading training data from {train_file}\")\n",
        "\n",
        "        with open(train_file, 'r', encoding='utf-8') as f:\n",
        "            train_data = json.load(f)\n",
        "\n",
        "        eval_data = None\n",
        "        if eval_file and os.path.exists(eval_file):\n",
        "            logger.info(f\"Loading evaluation data from {eval_file}\")\n",
        "            with open(eval_file, 'r', encoding='utf-8') as f:\n",
        "                eval_data = json.load(f)\n",
        "        else:\n",
        "            # Splitting training data for evaluation.\n",
        "            split_idx = int(len(train_data) * 0.9)\n",
        "            eval_data = train_data[split_idx:]\n",
        "            train_data = train_data[:split_idx]\n",
        "            logger.info(f\"Split training data: {len(train_data)} train, {len(eval_data)} eval\")\n",
        "\n",
        "\n",
        "        train_dataset = Dataset.from_list(train_data)\n",
        "        eval_dataset = Dataset.from_list(eval_data)\n",
        "\n",
        "        # Format the samples first to create a text field.\n",
        "        train_dataset = train_dataset.map(\n",
        "            self.format_sample,\n",
        "            remove_columns=train_dataset.column_names,\n",
        "            desc=\"Formatting training data\"\n",
        "        )\n",
        "\n",
        "        eval_dataset = eval_dataset.map(\n",
        "            self.format_sample,\n",
        "            remove_columns=eval_dataset.column_names,\n",
        "            desc=\"Formatting evaluation data\"\n",
        "        )\n",
        "\n",
        "        # Tokenize.\n",
        "        train_dataset = train_dataset.map(\n",
        "            self.tokenize_sample,\n",
        "            remove_columns=[\"text\"],\n",
        "            desc=\"Tokenizing training data\"\n",
        "        )\n",
        "\n",
        "        eval_dataset = eval_dataset.map(\n",
        "            self.tokenize_sample,\n",
        "            remove_columns=[\"text\"],\n",
        "            desc=\"Tokenizing evaluation data\"\n",
        "        )\n",
        "\n",
        "        return DatasetDict({\n",
        "            \"train\": train_dataset,\n",
        "            \"eval\": eval_dataset\n",
        "        })\n",
        "\n",
        "    # Formatting the sample.\n",
        "    def format_sample(self, sample: Dict[str, Any]) -> Dict[str, str]:\n",
        "        instruction = sample.get(\"instruction\", \"\")\n",
        "        output = sample.get(\"output\", \"\")\n",
        "        cot_reasoning = sample.get(\"cot_reasoning\", \"\") if self.config.use_cot else \"\"\n",
        "\n",
        "        # Formatted text.\n",
        "        human_part = self.config.instruction_template.format(instruction=instruction)\n",
        "\n",
        "        if self.config.use_cot and cot_reasoning:\n",
        "            # Including the CoT reasoning.\n",
        "            cot_part = self.config.cot_template.format(cot_reasoning=cot_reasoning)\n",
        "            response_part = self.config.response_template.format(output=output)\n",
        "            full_text = human_part + cot_part + response_part\n",
        "        else:\n",
        "            # Standard format without CoT.\n",
        "            response_part = self.config.response_template.format(output=output)\n",
        "            full_text = human_part + response_part\n",
        "\n",
        "        return {\"text\": full_text}\n",
        "\n",
        "# Model trainer class that handles the entire training process.\n",
        "class ModelTrainer:\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_config: ModelConfig,\n",
        "        lora_config: LoRAConfig,\n",
        "        training_config: TrainingConfig,\n",
        "        data_config: DataConfig\n",
        "    ):\n",
        "        self.model_config = model_config\n",
        "        self.lora_config = lora_config\n",
        "        self.training_config = training_config\n",
        "        self.data_config = data_config\n",
        "\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.peft_model = None\n",
        "\n",
        "    # Setting up quantization configuration.\n",
        "    def setup_quantization_config(self) -> Optional[BitsAndBytesConfig]:\n",
        "        if self.model_config.use_4bit:\n",
        "            logger.info(\"Setting up 4-bit quantization.\")\n",
        "            return BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_compute_dtype=getattr(torch, self.model_config.bnb_4bit_compute_dtype),\n",
        "                bnb_4bit_use_double_quant=self.model_config.use_nested_quant,\n",
        "                bnb_4bit_quant_type=self.model_config.bnb_4bit_quant_type,\n",
        "            )\n",
        "        elif self.model_config.use_8bit:\n",
        "            logger.info(\"Setting up 8-bit quantization.\")\n",
        "            return BitsAndBytesConfig(load_in_8bit=True)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    # Optimal device map based on GPU memory.\n",
        "    def get_optimal_device_map(self):\n",
        "        if not torch.cuda.is_available():\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "            print(f\"Detected GPU memory: {gpu_memory:.1f} GB\")\n",
        "\n",
        "            if gpu_memory < 12:\n",
        "                print(\"Limited GPU memory detected, using simple device mapping.\")\n",
        "                return {\"\": 0}\n",
        "            else:\n",
        "                return \"auto\"\n",
        "        except:\n",
        "            return {\"\": 0}\n",
        "\n",
        "    # Loading the base model and tokenizer.\n",
        "    def load_model_and_tokenizer(self):\n",
        "        logger.info(f\"Loading model: {self.model_config.model_name}\")\n",
        "\n",
        "        # Load tokenizer\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                self.model_config.model_name,\n",
        "                trust_remote_code=True,\n",
        "                padding_side=\"right\",\n",
        "                use_fast=False\n",
        "            )\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to load tokenizer: {e}\")\n",
        "            # Trying with a fallback tokenizer.\n",
        "            logger.info(\"Trying fallback tokenizer.\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                \"microsoft/DialoGPT-medium\",\n",
        "                trust_remote_code=True,\n",
        "                padding_side=\"right\",\n",
        "                use_fast=False\n",
        "            )\n",
        "\n",
        "        # Setting up quantization with better error handling.\n",
        "        quantization_config = None\n",
        "        try:\n",
        "            quantization_config = self.setup_quantization_config()\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Quantization setup failed: {e}\")\n",
        "            logger.info(\"Continuing without quantization.\")\n",
        "            self.model_config.use_4bit = False\n",
        "            self.model_config.use_8bit = False\n",
        "\n",
        "        device_map = self.get_optimal_device_map()\n",
        "\n",
        "        # Torch dtype.\n",
        "        if self.model_config.torch_dtype == \"auto\":\n",
        "            torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "        else:\n",
        "            torch_dtype = getattr(torch, self.model_config.torch_dtype)\n",
        "\n",
        "        print(f\"Using device map: {device_map}\")\n",
        "        print(f\"Using quantization: {quantization_config is not None}\")\n",
        "\n",
        "        try:\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_config.model_name,\n",
        "                quantization_config=quantization_config,\n",
        "                device_map=device_map,\n",
        "                torch_dtype=torch_dtype,\n",
        "                trust_remote_code=True,\n",
        "                low_cpu_mem_usage=self.model_config.low_cpu_mem_usage,\n",
        "                attn_implementation=\"flash_attention_2\" if torch.cuda.is_available() else None\n",
        "            )\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Failed to load model with flash attention: {e}\")\n",
        "            logger.info(\"Retrying without flash attention.\")\n",
        "            try:\n",
        "                self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                    self.model_config.model_name,\n",
        "                    quantization_config=quantization_config,\n",
        "                    device_map=device_map,\n",
        "                    torch_dtype=torch_dtype,\n",
        "                    trust_remote_code=True,\n",
        "                    low_cpu_mem_usage=self.model_config.low_cpu_mem_usage\n",
        "                )\n",
        "            except Exception as e2:\n",
        "                logger.warning(f\"Failed with device mapping: {e2}\")\n",
        "                logger.info(\"Trying with simpler configuration.\")\n",
        "                self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                    self.model_config.model_name,\n",
        "                    torch_dtype=torch.float32,\n",
        "                    trust_remote_code=True,\n",
        "                    low_cpu_mem_usage=True\n",
        "                )\n",
        "\n",
        "        if quantization_config is not None:\n",
        "            try:\n",
        "                self.model = prepare_model_for_kbit_training(self.model)\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Failed to prepare model for k-bit training: {e}\")\n",
        "\n",
        "        try:\n",
        "            self.model.gradient_checkpointing_enable()\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Failed to enable gradient checkpointing: {e}\")\n",
        "\n",
        "        logger.info(\"Model and tokenizer loaded.\")\n",
        "\n",
        "    # Target modules for Lora.\n",
        "    def get_target_modules_for_model(self, model):\n",
        "        model_name = self.model_config.model_name.lower()\n",
        "\n",
        "        module_names = []\n",
        "        for name, module in model.named_modules():\n",
        "            if hasattr(module, 'weight') and len(list(module.parameters())) > 0:\n",
        "                module_names.append(name.split('.')[-1])\n",
        "\n",
        "        # Removing duplicates and common modules we don't want to target.\n",
        "        unique_modules = list(set(module_names))\n",
        "        exclude_modules = ['layernorm', 'ln', 'bias', 'embedding', 'lm_head', 'embed', 'norm']\n",
        "        target_candidates = [m for m in unique_modules if not any(ex in m.lower() for ex in exclude_modules)]\n",
        "\n",
        "        print(f\"Available modules in model: {target_candidates}\")\n",
        "\n",
        "        # Defining the target modules.\n",
        "        if 'llama' in model_name or 'alpaca' in model_name:\n",
        "            # Llama/Alpaca models.\n",
        "            llama_targets = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "            available_targets = [t for t in llama_targets if t in target_candidates]\n",
        "            if available_targets:\n",
        "                return available_targets\n",
        "\n",
        "        elif 'gpt' in model_name or 'dialo' in model_name:\n",
        "            # GPT models.\n",
        "            gpt_targets = [\"c_attn\", \"c_proj\", \"c_fc\", \"attn\", \"mlp\"]\n",
        "            available_targets = [t for t in gpt_targets if t in target_candidates]\n",
        "            if available_targets:\n",
        "                return available_targets\n",
        "\n",
        "        elif 'bert' in model_name:\n",
        "            # BERT models.\n",
        "            bert_targets = [\"query\", \"key\", \"value\", \"dense\"]\n",
        "            available_targets = [t for t in bert_targets if t in target_candidates]\n",
        "            if available_targets:\n",
        "                return available_targets\n",
        "\n",
        "        # Fallback if no specific targets are found.\n",
        "        linear_patterns = [\"linear\", \"proj\", \"fc\", \"dense\", \"attn\"]\n",
        "        fallback_targets = []\n",
        "        for pattern in linear_patterns:\n",
        "            matches = [m for m in target_candidates if pattern in m.lower()]\n",
        "            fallback_targets.extend(matches)\n",
        "\n",
        "        if fallback_targets:\n",
        "            # Takes the first few unique matches.\n",
        "            return list(set(fallback_targets))[:4]\n",
        "\n",
        "        # Last resort.\n",
        "        if target_candidates:\n",
        "            print(f\"Using fallback target modules: {target_candidates[:3]}\")\n",
        "            return target_candidates[:3]\n",
        "\n",
        "        # If all else fails, it returns empty list and let PEFT handle it\n",
        "        print(\"Could not determine target modules, using PEFT defaults.\")\n",
        "        return []\n",
        "\n",
        "    # Setting up Lora.\n",
        "    def setup_lora(self):\n",
        "        logger.info(\"Setting up LoRA configuration\")\n",
        "\n",
        "        if self.lora_config.lora_r == 0:\n",
        "            logger.info(\"LoRA disabled (rank=0), using full fine-tuning\")\n",
        "            self.peft_model = self.model\n",
        "            return\n",
        "\n",
        "        # Getting the appropriate target modules for this model.\n",
        "        target_modules = self.get_target_modules_for_model(self.model)\n",
        "\n",
        "        if not target_modules:\n",
        "            # If no target modules are found, letting PEFT auto-detect.\n",
        "            target_modules = None\n",
        "            print(\"Using PEFT auto-detection for target modules.\")\n",
        "        else:\n",
        "            print(f\"Using target modules: {target_modules}\")\n",
        "\n",
        "        peft_config = LoraConfig(\n",
        "            r=self.lora_config.lora_r,\n",
        "            lora_alpha=self.lora_config.lora_alpha,\n",
        "            lora_dropout=self.lora_config.lora_dropout,\n",
        "            bias=self.lora_config.bias,\n",
        "            task_type=TaskType.CAUSAL_LM,\n",
        "            target_modules=target_modules,\n",
        "            inference_mode=self.lora_config.inference_mode\n",
        "        )\n",
        "\n",
        "        # Applying Lora.\n",
        "        try:\n",
        "            self.peft_model = get_peft_model(self.model, peft_config)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Failed to apply LoRA with auto-detected modules: {e}\")\n",
        "            logger.info(\"Trying with broader target module selection.\")\n",
        "\n",
        "            # Fallback to broader target modules.\n",
        "            fallback_targets = [\"linear\", \"Linear\"]\n",
        "            peft_config.target_modules = fallback_targets\n",
        "\n",
        "            try:\n",
        "                self.peft_model = get_peft_model(self.model, peft_config)\n",
        "            except Exception as e2:\n",
        "                logger.warning(f\"Fallback also failed: {e2}\")\n",
        "                logger.info(\"Using model without LoRA.\")\n",
        "                self.peft_model = self.model\n",
        "                return\n",
        "\n",
        "        # Trainable parameters.\n",
        "        try:\n",
        "            self.peft_model.print_trainable_parameters()\n",
        "        except:\n",
        "            logger.info(\"Model ready for training.\")\n",
        "\n",
        "        logger.info(\"LoRA applied.\")\n",
        "\n",
        "    def setup_training_arguments(self, output_dir: str, dataset_size: int) -> TrainingArguments:\n",
        "        if self.training_config.eval_steps == -1:\n",
        "            self.training_config.eval_steps = max(50, dataset_size // (self.training_config.per_device_train_batch_size * 10))\n",
        "\n",
        "        if self.training_config.save_steps == -1:\n",
        "            self.training_config.save_steps = self.training_config.eval_steps * 2\n",
        "\n",
        "        # Max steps if not provided.\n",
        "        if self.training_config.max_steps == -1:\n",
        "            steps_per_epoch = math.ceil(dataset_size / (\n",
        "                self.training_config.per_device_train_batch_size *\n",
        "                self.training_config.gradient_accumulation_steps\n",
        "            ))\n",
        "            self.training_config.max_steps = steps_per_epoch * self.training_config.num_train_epochs\n",
        "\n",
        "        return TrainingArguments(\n",
        "            output_dir=output_dir,\n",
        "            num_train_epochs=self.training_config.num_train_epochs,\n",
        "            per_device_train_batch_size=self.training_config.per_device_train_batch_size,\n",
        "            per_device_eval_batch_size=self.training_config.per_device_eval_batch_size,\n",
        "            gradient_accumulation_steps=self.training_config.gradient_accumulation_steps,\n",
        "            learning_rate=self.training_config.learning_rate,\n",
        "            weight_decay=self.training_config.weight_decay,\n",
        "            lr_scheduler_type=self.training_config.lr_scheduler_type,\n",
        "            warmup_ratio=self.training_config.warmup_ratio,\n",
        "            max_steps=self.training_config.max_steps,\n",
        "            eval_steps=self.training_config.eval_steps,\n",
        "            save_steps=self.training_config.save_steps,\n",
        "            logging_steps=self.training_config.logging_steps,\n",
        "            eval_strategy=self.training_config.evaluation_strategy,\n",
        "            save_strategy=self.training_config.save_strategy,\n",
        "            load_best_model_at_end=self.training_config.load_best_model_at_end,\n",
        "            metric_for_best_model=self.training_config.metric_for_best_model,\n",
        "            greater_is_better=self.training_config.greater_is_better,\n",
        "            report_to=self.training_config.report_to,\n",
        "            dataloader_num_workers=self.training_config.dataloader_num_workers,\n",
        "            fp16=self.training_config.fp16,\n",
        "            bf16=self.training_config.bf16,\n",
        "            max_grad_norm=self.training_config.max_grad_norm,\n",
        "            seed=self.training_config.seed,\n",
        "            data_seed=self.training_config.data_seed,\n",
        "            remove_unused_columns=self.data_config.remove_unused_columns,\n",
        "            ddp_find_unused_parameters=False,\n",
        "            group_by_length=True,\n",
        "            dataloader_pin_memory=True,\n",
        "        )\n",
        "\n",
        "    def compute_metrics(self, eval_pred):\n",
        "        predictions, labels = eval_pred\n",
        "\n",
        "        # In case that the predictions might be logits.\n",
        "        if len(predictions.shape) > 2:\n",
        "            predictions = predictions.argmax(-1)\n",
        "\n",
        "        # Decode predictions and labels to text.\n",
        "        decoded_preds = []\n",
        "        decoded_labels = []\n",
        "\n",
        "        for pred, label in zip(predictions, labels):\n",
        "            # Removing 100 tokens from the labels.\n",
        "            label_filtered = [token for token in label if token != -100]\n",
        "\n",
        "            try:\n",
        "                decoded_pred = self.tokenizer.decode(pred, skip_special_tokens=True)\n",
        "                decoded_label = self.tokenizer.decode(label_filtered, skip_special_tokens=True)\n",
        "\n",
        "                decoded_preds.append(decoded_pred)\n",
        "                decoded_labels.append(decoded_label)\n",
        "            except:\n",
        "                decoded_preds.append(\"\")\n",
        "                decoded_labels.append(\"\")\n",
        "\n",
        "        # Metrics.\n",
        "        pred_lengths = [len(pred.split()) for pred in decoded_preds if pred]\n",
        "        label_lengths = [len(label.split()) for label in decoded_labels if label]\n",
        "\n",
        "        return {\n",
        "            \"avg_pred_length\": np.mean(pred_lengths) if pred_lengths else 0,\n",
        "            \"avg_label_length\": np.mean(label_lengths) if label_lengths else 0,\n",
        "            \"length_ratio\": (np.mean(pred_lengths) / np.mean(label_lengths)) if (pred_lengths and label_lengths and np.mean(label_lengths) > 0) else 0\n",
        "        }\n",
        "\n",
        "    def train(self, train_file: str, eval_file: Optional[str], output_dir: str):\n",
        "        logger.info(\"Starting training process.\")\n",
        "\n",
        "        # Output directory.\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        self.load_model_and_tokenizer()\n",
        "\n",
        "        # Setting up LoRA.\n",
        "        self.setup_lora()\n",
        "\n",
        "        # Loading the data.\n",
        "        data_processor = MedicalDataProcessor(self.data_config, self.tokenizer)\n",
        "        dataset = data_processor.load_dataset(train_file, eval_file)\n",
        "\n",
        "        logger.info(f\"Training samples: {len(dataset['train'])}\")\n",
        "        logger.info(f\"Evaluation samples: {len(dataset['eval'])}\")\n",
        "\n",
        "        # Training arguments.\n",
        "        training_args = self.setup_training_arguments(output_dir, len(dataset['train']))\n",
        "\n",
        "        # Setting up data collator.\n",
        "        try:\n",
        "            from transformers import default_data_collator\n",
        "            data_collator = default_data_collator\n",
        "            logger.info(\"Using default data collator with pre-padded sequences.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Failed to setup default data collator: {e}\")\n",
        "\n",
        "            # Fallback to data collator for completion only LM.\n",
        "            try:\n",
        "                from transformers import DataCollatorForLanguageModeling\n",
        "                data_collator = DataCollatorForLanguageModeling(\n",
        "                    tokenizer=self.tokenizer,\n",
        "                    mlm=False,\n",
        "                    pad_to_multiple_of=None,\n",
        "                )\n",
        "                logger.info(\"Using DataCollatorForLanguageModeling\")\n",
        "            except Exception as e2:\n",
        "                logger.warning(f\"Failed to setup DataCollatorForLanguageModeling: {e2}\")\n",
        "\n",
        "                # Final fallback to a simple data collator.\n",
        "                def simple_data_collator(features):\n",
        "                    import torch\n",
        "                    batch = {}\n",
        "\n",
        "                    # Getting all keys from the first feature.\n",
        "                    keys = features[0].keys()\n",
        "\n",
        "                    for key in keys:\n",
        "                        batch[key] = torch.stack([torch.tensor(f[key]) for f in features])\n",
        "\n",
        "                    return batch\n",
        "\n",
        "                data_collator = simple_data_collator\n",
        "                logger.info(\"Using custom simple data collator.\")\n",
        "\n",
        "        # Reducing the number of workers to avoid multiprocessing issues.\n",
        "        training_args.dataloader_num_workers = 0\n",
        "\n",
        "        # Setup trainer with SFTTrainer or standard Trainer.\n",
        "        try:\n",
        "            trainer = SFTTrainer(\n",
        "                model=self.peft_model,\n",
        "                args=training_args,\n",
        "                train_dataset=dataset[\"train\"],\n",
        "                eval_dataset=dataset[\"eval\"],\n",
        "                data_collator=data_collator,\n",
        "                compute_metrics=self.compute_metrics,\n",
        "                callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "                dataset_text_field=\"text\",\n",
        "                packing=False,\n",
        "            )\n",
        "\n",
        "            # Set tokenizer manually if needed.\n",
        "            if hasattr(trainer, 'tokenizer'):\n",
        "                trainer.tokenizer = self.tokenizer\n",
        "            else:\n",
        "                setattr(trainer, 'tokenizer', self.tokenizer)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"SFTTrainer failed: {e}\")\n",
        "            logger.info(\"Falling back to standard Trainer.\")\n",
        "\n",
        "            # Fallback to standard trainer.\n",
        "            try:\n",
        "                trainer = Trainer(\n",
        "                    model=self.peft_model,\n",
        "                    args=training_args,\n",
        "                    train_dataset=dataset[\"train\"],\n",
        "                    eval_dataset=dataset[\"eval\"],\n",
        "                    data_collator=data_collator,\n",
        "                    compute_metrics=self.compute_metrics,\n",
        "                    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "                    processing_class=self.tokenizer,\n",
        "                )\n",
        "            except Exception as e2:\n",
        "                logger.warning(f\"Standard Trainer with processing_class failed: {e2}\")\n",
        "                trainer = Trainer(\n",
        "                    model=self.peft_model,\n",
        "                    args=training_args,\n",
        "                    train_dataset=dataset[\"train\"],\n",
        "                    eval_dataset=dataset[\"eval\"],\n",
        "                    data_collator=data_collator,\n",
        "                    compute_metrics=self.compute_metrics,\n",
        "                    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "                )\n",
        "                # Set tokenizer as attribute.\n",
        "                setattr(trainer, 'tokenizer', self.tokenizer)\n",
        "\n",
        "        self.save_configs(output_dir)\n",
        "\n",
        "        # Start training.\n",
        "        logger.info(\"Starting training.\")\n",
        "        train_result = trainer.train()\n",
        "\n",
        "        logger.info(\"Saving final model.\")\n",
        "        trainer.save_model(output_dir)\n",
        "\n",
        "        # Training metrics.\n",
        "        train_metrics = train_result.metrics\n",
        "        trainer.log_metrics(\"train\", train_metrics)\n",
        "        trainer.save_metrics(\"train\", train_metrics)\n",
        "\n",
        "        logger.info(\"Running final evaluation.\")\n",
        "        eval_metrics = trainer.evaluate()\n",
        "        trainer.log_metrics(\"eval\", eval_metrics)\n",
        "        trainer.save_metrics(\"eval\", eval_metrics)\n",
        "\n",
        "        # Save tokenizer.\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        logger.info(f\"Training completed successfully. Model saved to {output_dir}\")\n",
        "\n",
        "        return train_result, eval_metrics\n",
        "\n",
        "    def save_configs(self, output_dir: str):\n",
        "        configs = {\n",
        "            \"model_config\": self.model_config.__dict__,\n",
        "            \"lora_config\": self.lora_config.__dict__,\n",
        "            \"training_config\": self.training_config.__dict__,\n",
        "            \"data_config\": self.data_config.__dict__\n",
        "        }\n",
        "\n",
        "        config_path = os.path.join(output_dir, \"training_config.json\")\n",
        "        with open(config_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(configs, f, indent=2)\n",
        "\n",
        "        logger.info(f\"Training configurations saved to {config_path}\")\n",
        "\n",
        "# Google Colab.\n",
        "def upload_files():\n",
        "    from google.colab import files\n",
        "    print(\"Please select your training file to upload:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    uploaded_files = {}\n",
        "    for filename, content in uploaded.items():\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(content)\n",
        "        uploaded_files[filename] = filename\n",
        "        print(f\"Uploaded and saved: {filename}\")\n",
        "\n",
        "    return uploaded_files\n",
        "\n",
        "def mount_google_drive():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive successful.\")\n",
        "\n",
        "def download_from_drive(file_path_in_drive, local_path):\n",
        "    import shutil\n",
        "\n",
        "    full_drive_path = f\"/content/drive/MyDrive/{file_path_in_drive}\"\n",
        "\n",
        "    if os.path.exists(full_drive_path):\n",
        "        shutil.copy2(full_drive_path, local_path)\n",
        "        print(f\"File downloaded from {full_drive_path} to {local_path}\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"File not found in Google Drive: {full_drive_path}\")\n",
        "        return False\n",
        "\n",
        "# Getting the training file.\n",
        "def get_training_file(method=\"upload\"):\n",
        "    if method == \"upload\":\n",
        "        print(\"File Upload method.\")\n",
        "        uploaded_files = upload_files()\n",
        "\n",
        "        train_file = None\n",
        "        eval_file = None\n",
        "\n",
        "        for filename in uploaded_files.keys():\n",
        "            if \"train\" in filename.lower() and filename.endswith('.json'):\n",
        "                train_file = filename\n",
        "            elif \"eval\" in filename.lower() and filename.endswith('.json'):\n",
        "                eval_file = filename\n",
        "\n",
        "        if not train_file:\n",
        "            json_files = [f for f in uploaded_files.keys() if f.endswith('.json')]\n",
        "            if json_files:\n",
        "                train_file = json_files[0]\n",
        "                print(f\"Using {train_file} as training file.\")\n",
        "\n",
        "        return train_file, eval_file\n",
        "\n",
        "    elif method == \"drive\":\n",
        "        print(\"Google Drive method.\")\n",
        "        mount_google_drive()\n",
        "\n",
        "        train_path = input(\"Enter the path to your training file in Google Drive: \")\n",
        "        eval_path = input(\"Enter the path to your evaluation file in Google Drive: \")\n",
        "\n",
        "        local_train_file = \"./train_data.json\"\n",
        "        local_eval_file = None\n",
        "\n",
        "        if download_from_drive(train_path, local_train_file):\n",
        "            if eval_path.strip():\n",
        "                local_eval_file = \"./eval_data.json\"\n",
        "                if not download_from_drive(eval_path, local_eval_file):\n",
        "                    local_eval_file = None\n",
        "            return local_train_file, local_eval_file\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Could not download training file: {train_path}\")\n",
        "\n",
        "    else:\n",
        "        if os.path.exists(method):\n",
        "            return method, None\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"File not found: {method}\")\n",
        "\n",
        "\n",
        "def run_training(\n",
        "    file_method: str = \"upload\",\n",
        "    train_file_drive_path: Optional[str] = None,\n",
        "    eval_file_drive_path: Optional[str] = None,\n",
        "    output_dir: str = \"./fine_tuned_model\",\n",
        "\n",
        "    # Model configuration.\n",
        "    model_name: str = \"skumar9/Llama-medx_v3.2\",\n",
        "    use_4bit: bool = True,\n",
        "    use_8bit: bool = False,\n",
        "\n",
        "    # Lora configuration.\n",
        "    lora_r: int = 64,\n",
        "    lora_alpha: int = 16,\n",
        "    lora_dropout: float = 0.1,\n",
        "\n",
        "    # Training configuration.\n",
        "    epochs: int = 3,\n",
        "    batch_size: int = 2,\n",
        "    learning_rate: float = 2e-5,\n",
        "    eval_steps: int = 100,\n",
        "    save_steps: int = 200,\n",
        "\n",
        "    # Data configuration.\n",
        "    max_seq_length: int = 2048,\n",
        "    use_cot: bool = True,\n",
        "\n",
        "    # Experiment tracking.\n",
        "    wandb_project: Optional[str] = None,\n",
        "    run_name: Optional[str] = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Run the complete fine-tuning process with flexible file input methods.\n",
        "\n",
        "    Args:\n",
        "        file_method: How to get training files:\n",
        "            - \"upload\": Upload files directly via browser\n",
        "            - \"drive\": Download from Google Drive\n",
        "            - Or provide direct file path to existing file\n",
        "        train_file_drive_path: Path to training file in Google Drive (if using \"drive\" method)\n",
        "        eval_file_drive_path: Path to evaluation file in Google Drive (optional)\n",
        "        output_dir: Local directory to save the fine-tuned model\n",
        "        ... (other parameters as documented in the original code)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Starting Medical Chatbot Fine-tuning Process.\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Getting the training files.\n",
        "    if file_method == \"upload\":\n",
        "        train_file, eval_file = get_training_file(\"upload\")\n",
        "    elif file_method == \"drive\":\n",
        "        if train_file_drive_path:\n",
        "            # Use provided paths\n",
        "            mount_google_drive()\n",
        "            train_file = \"./train_data.json\"\n",
        "            eval_file = None\n",
        "\n",
        "            if not download_from_drive(train_file_drive_path, train_file):\n",
        "                raise FileNotFoundError(f\"Could not download training file: {train_file_drive_path}\")\n",
        "\n",
        "            if eval_file_drive_path:\n",
        "                eval_file = \"./eval_data.json\"\n",
        "                if not download_from_drive(eval_file_drive_path, eval_file):\n",
        "                    eval_file = None\n",
        "        else:\n",
        "            # Interactive mode.\n",
        "            train_file, eval_file = get_training_file(\"drive\")\n",
        "    else:\n",
        "        train_file, eval_file = get_training_file(file_method)\n",
        "\n",
        "    if not train_file:\n",
        "        raise ValueError(\"No training file provided or found.\")\n",
        "\n",
        "    print(f\"Training file: {train_file}\")\n",
        "    if eval_file:\n",
        "        print(f\"Evaluation file: {eval_file}\")\n",
        "    else:\n",
        "        print(\"No evaluation file provided, we will split training data.\")\n",
        "\n",
        "    # Setup wandb.\n",
        "    if wandb_project:\n",
        "        os.environ[\"WANDB_PROJECT\"] = wandb_project\n",
        "        if run_name:\n",
        "            os.environ[\"WANDB_RUN_NAME\"] = run_name\n",
        "\n",
        "    # Create configurations.\n",
        "    model_config = ModelConfig(\n",
        "        model_name=model_name,\n",
        "        use_4bit=use_4bit,\n",
        "        use_8bit=use_8bit\n",
        "    )\n",
        "\n",
        "    lora_config = LoRAConfig(\n",
        "        lora_r=lora_r,\n",
        "        lora_alpha=lora_alpha,\n",
        "        lora_dropout=lora_dropout\n",
        "    )\n",
        "\n",
        "    training_config = TrainingConfig(\n",
        "        num_train_epochs=epochs,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        learning_rate=learning_rate,\n",
        "        eval_steps=eval_steps,\n",
        "        save_steps=save_steps,\n",
        "        report_to=[\"wandb\"] if wandb_project else [\"tensorboard\"]\n",
        "    )\n",
        "\n",
        "    data_config = DataConfig(\n",
        "        max_seq_length=max_seq_length,\n",
        "        use_cot=use_cot\n",
        "    )\n",
        "\n",
        "    # Initialize trainer.\n",
        "    trainer = ModelTrainer(model_config, lora_config, training_config, data_config)\n",
        "\n",
        "    try:\n",
        "        # Start training.\n",
        "        train_result, eval_metrics = trainer.train(\n",
        "            train_file,\n",
        "            eval_file,\n",
        "            output_dir\n",
        "        )\n",
        "\n",
        "        # Final results.\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Training completed.\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Final training loss: {train_result.training_loss:.4f}\")\n",
        "        print(f\"Final evaluation loss: {eval_metrics['eval_loss']:.4f}\")\n",
        "        print(f\"Model saved to: {output_dir}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return train_result, eval_metrics\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Training failed: {e}\")\n",
        "        raise\n",
        "\n",
        "# Example functions.\n",
        "def start_training_with_upload():\n",
        "    print(\"Quick Start: Upload File Method.\")\n",
        "    print(\"This will prompt you to upload your train_with_cot.json file directly.\")\n",
        "\n",
        "    try:\n",
        "        train_result, eval_metrics = run_training(\n",
        "            file_method=\"upload\",\n",
        "            epochs=1,\n",
        "            batch_size=1,\n",
        "            eval_steps=10,\n",
        "            save_steps=20,\n",
        "            output_dir=\"./uploaded_model\",\n",
        "            use_4bit=False,\n",
        "            use_8bit=False,\n",
        "            max_seq_length=512,\n",
        "        )\n",
        "\n",
        "        return train_result, eval_metrics\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Training failed: {e}\")\n",
        "        print(\"\\nTroubleshooting suggestions:\")\n",
        "        print(\"1. Try restarting the runtime.\")\n",
        "        print(\"2. Try the CPU-only version with smaller parameters.\")\n",
        "        print(\"3. Try a smaller model if memory is the issue.\")\n",
        "\n",
        "        # Offer different fallback options\n",
        "        print(\"\\nChoose a fallback option:\")\n",
        "        print(\"1. CPU-only mode (c)\")\n",
        "        print(\"2. Smaller model (s)\")\n",
        "        print(\"3. Exit (e)\")\n",
        "\n",
        "        response = input(\"Enter your choice (c/s/e): \").lower()\n",
        "        if response == 'c':\n",
        "            return start_training_cpu_mode()\n",
        "        elif response == 's':\n",
        "            return start_training_small_model()\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "# Smaller model training for memory efficiency.\n",
        "def start_training_small_model():\n",
        "    print(\"Starting with smaller model.\")\n",
        "\n",
        "    train_result, eval_metrics = run_training(\n",
        "        file_method=\"upload\",\n",
        "        model_name=\"microsoft/DialoGPT-small\",\n",
        "        epochs=2,\n",
        "        batch_size=1,\n",
        "        eval_steps=10,\n",
        "        save_steps=20,\n",
        "        output_dir=\"./small_model\",\n",
        "        use_4bit=True,\n",
        "        use_8bit=False,\n",
        "        max_seq_length=128,\n",
        "        learning_rate=5e-5,\n",
        "        lora_r=8,\n",
        "        lora_alpha=8,\n",
        "    )\n",
        "\n",
        "    return train_result, eval_metrics\n",
        "\n",
        "# Basic training mode with conservative settings.\n",
        "def start_training_basic_mode():\n",
        "    print(\"Starting basic training mode.\")\n",
        "\n",
        "    train_result, eval_metrics = run_training(\n",
        "        file_method=\"upload\",\n",
        "        model_name=\"microsoft/DialoGPT-medium\",\n",
        "        epochs=1,\n",
        "        batch_size=1,\n",
        "        eval_steps=5,\n",
        "        save_steps=10,\n",
        "        output_dir=\"./basic_model\",\n",
        "        use_4bit=True,\n",
        "        use_8bit=False,\n",
        "        max_seq_length=256,\n",
        "        learning_rate=5e-6,\n",
        "        lora_r=4,\n",
        "        lora_alpha=4,\n",
        "    )\n",
        "\n",
        "    return train_result, eval_metrics\n",
        "\n",
        "# CPU training mode for fallback.\n",
        "def start_training_cpu_mode():\n",
        "    print(\"Starting CPU-only training mode.\")\n",
        "\n",
        "    train_result, eval_metrics = run_training(\n",
        "        file_method=\"upload\",\n",
        "        epochs=1,\n",
        "        batch_size=1,\n",
        "        eval_steps=5,\n",
        "        save_steps=10,\n",
        "        output_dir=\"./cpu_model\",\n",
        "        use_4bit=False,\n",
        "        use_8bit=False,\n",
        "        max_seq_length=256,\n",
        "        learning_rate=5e-5,\n",
        "    )\n",
        "\n",
        "    return train_result, eval_metrics\n",
        "\n",
        "def start_training_with_drive():\n",
        "    print(\"Google Drive Method.\")\n",
        "    print(\"This will mount Google Drive and ask for your file paths.\")\n",
        "\n",
        "    train_result, eval_metrics = run_training(\n",
        "        file_method=\"drive\",\n",
        "        epochs=2,\n",
        "        batch_size=4,\n",
        "        eval_steps=50,\n",
        "        save_steps=100,\n",
        "        output_dir=\"./drive_model\"\n",
        "    )\n",
        "\n",
        "    return train_result, eval_metrics\n",
        "\n",
        "# Function to start training with Google Drive paths.\n",
        "def start_training_with_drive_paths(train_path, eval_path=None):\n",
        "    print(f\"Google Drive Method with provided paths.\")\n",
        "    print(f\"Training file: {train_path}\")\n",
        "    if eval_path:\n",
        "        print(f\"Evaluation file: {eval_path}\")\n",
        "\n",
        "    train_result, eval_metrics = run_training(\n",
        "        file_method=\"drive\",\n",
        "        train_file_drive_path=train_path,\n",
        "        eval_file_drive_path=eval_path,\n",
        "        epochs=2,\n",
        "        batch_size=4,\n",
        "        eval_steps=50,\n",
        "        save_steps=100,\n",
        "        output_dir=\"./drive_model\"\n",
        "    )\n",
        "\n",
        "    return train_result, eval_metrics\n",
        "\n",
        "def example_custom_training():\n",
        "    print(\"Custom Training configuration.\")\n",
        "\n",
        "    train_result, eval_metrics = run_training(\n",
        "        file_method=\"upload\",\n",
        "\n",
        "        # Model settings.\n",
        "        model_name=\"skumar9/Llama-medx_v3.2\",\n",
        "        use_4bit=True,\n",
        "\n",
        "        # Lora settings.\n",
        "        lora_r=32,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.1,\n",
        "\n",
        "        # Training settings.\n",
        "        epochs=3,\n",
        "        batch_size=2,\n",
        "        learning_rate=1e-5,\n",
        "        eval_steps=25,\n",
        "        save_steps=50,\n",
        "\n",
        "        # Data settings.\n",
        "        max_seq_length=1024,\n",
        "        use_cot=True,\n",
        "\n",
        "        output_dir=\"./custom_model\",\n",
        "\n",
        "        # wandb_project=\"medical-chatbot\",\n",
        "        # run_name=\"custom-experiment-1\"\n",
        "    )\n",
        "\n",
        "    return train_result, eval_metrics\n",
        "\n",
        "print(\"Fine-tuning loaded.\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Multiple ways to upload the file:\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n Basic:\")\n",
        "print(\"   start_training_basic_mode()\")\n",
        "print(\" Uses standard Trainer and works with any TRL version.\")\n",
        "\n",
        "print(\"\\n Small model mode:\")\n",
        "print(\"   start_training_small_model()\")\n",
        "print(\"DialoGPT-small with adaptive LoRA.\")\n",
        "\n",
        "print(\"\\n Upload file:\")\n",
        "print(\"   start_training_with_upload()\")\n",
        "print(\"Adapts to any model with smart error handling.\")\n",
        "\n",
        "print(\"\\n CPU-only mode:\")\n",
        "print(\"   start_training_cpu_mode()\")\n",
        "print(\" No GPU/quantization, works on any hardware.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Quick Fix for SFTTrainer error:\")\n",
        "print(\"   The trainer now falls back to standard Trainer.\")\n",
        "print(\"   Try: start_training_basic_mode()\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n Trainer compatability features:\")\n",
        "print(\"- Auto-detects SFTTrainer vs standard Trainer compatibility.\")\n",
        "print(\"- Falls back gracefully if SFTTrainer parameters don't match.\")\n",
        "print(\"- Works with any version of transformers/TRL.\")\n",
        "print(\"- Handles data collator compatibility issues.\")\n",
        "print(\"- Maximum compatibility mode available.\")\n",
        "\n",
        "start_training_small_model()\n",
        "\n",
        "# Loading the fine-tuned model.\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "def test_finetuned_model():\n",
        "    try:\n",
        "        print(\"Loading fine-tuned model.\")\n",
        "\n",
        "        # Loading the tokenizer and model.\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"./small_model\")\n",
        "        model = AutoModelForCausalLM.from_pretrained(\"./small_model\")\n",
        "\n",
        "        # Checking if the tokenizer has pad token.\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        print(\"Model loaded.\")\n",
        "\n",
        "        # Test with medical queries.\n",
        "        test_prompts = [\n",
        "            \"What are the symptoms of diabetes?\",\n",
        "            \"How is hypertension treated?\",\n",
        "            \"What causes chest pain?\",\n",
        "            \"Explain the difference between Type 1 and Type 2 diabetes.\"\n",
        "        ]\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Testing the fine-tuned medial model.\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        for i, prompt in enumerate(test_prompts, 1):\n",
        "            print(f\"\\n Test {i}: {prompt}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            try:\n",
        "                inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "                # Generating the response.\n",
        "                with torch.no_grad():\n",
        "                    outputs = model.generate(\n",
        "                        **inputs,\n",
        "                        max_length=200,\n",
        "                        do_sample=True,\n",
        "                        temperature=0.7,\n",
        "                        top_p=0.9,\n",
        "                        repetition_penalty=1.1,\n",
        "                        pad_token_id=tokenizer.pad_token_id,\n",
        "                        eos_token_id=tokenizer.eos_token_id\n",
        "                    )\n",
        "\n",
        "                # Decoding the response.\n",
        "                response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "                # Extracting the generated part.\n",
        "                if prompt in response:\n",
        "                    generated_text = response[len(prompt):].strip()\n",
        "                else:\n",
        "                    generated_text = response.strip()\n",
        "\n",
        "                print(f\"Response: {generated_text}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating response: {e}\")\n",
        "                continue\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        print(\"\\n Troubleshooting suggestions:\")\n",
        "        print(\"1. Make sure the model was saved correctly.\")\n",
        "        print(\"2. Check if the path './small_model' exists.\")\n",
        "        print(\"3. Try loading with different parameters.\")\n",
        "\n",
        "        # Try the alternative loading approach.\n",
        "        try:\n",
        "            print(\"\\nTrying alternative loading method.\")\n",
        "            from peft import PeftModel\n",
        "\n",
        "            base_model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-small\")\n",
        "            model = PeftModel.from_pretrained(base_model, \"./small_model\")\n",
        "            tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
        "\n",
        "            print(\"Alternative loading successful.\")\n",
        "\n",
        "            # Testing.\n",
        "            prompt = \"What are the symptoms of diabetes?\"\n",
        "            inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "            outputs = model.generate(**inputs, max_length=150, do_sample=True)\n",
        "            response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            print(f\"Response: {response}\")\n",
        "\n",
        "        except Exception as e2:\n",
        "            print(f\"Alternative loading also failed: {e2}\")\n",
        "\n",
        "def simple_test():\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"./small_model\")\n",
        "        model = AutoModelForCausalLM.from_pretrained(\"./small_model\")\n",
        "\n",
        "        # Simple test.\n",
        "        prompt = \"What are the symptoms of diabetes?\"\n",
        "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "        # With parameters.\n",
        "        outputs = model.generate(\n",
        "            inputs,\n",
        "            max_length=inputs.shape[1] + 50,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        print(f\"Prompt: {prompt}\")\n",
        "        print(f\"Response: {response}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "def check_model_files():\n",
        "    import os\n",
        "\n",
        "    model_path = \"./small_model\"\n",
        "    if os.path.exists(model_path):\n",
        "        files = os.listdir(model_path)\n",
        "        print(f\"Files in {model_path}:\")\n",
        "        for file in files:\n",
        "            print(f\"  - {file}\")\n",
        "    else:\n",
        "        print(f\"Model path {model_path} does not exist.\")\n",
        "\n",
        "# Tests.\n",
        "print(\"Checking model files.\")\n",
        "check_model_files()\n",
        "\n",
        "print(\"Running simple test.\")\n",
        "simple_test()\n",
        "\n",
        "print(\"Running comprehensive test.\")\n",
        "test_finetuned_model()"
      ]
    }
  ]
}