{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>long_answer</th>\n",
       "      <th>final_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21645374</th>\n",
       "      <td>Do mitochondria play a role in remodelling lac...</td>\n",
       "      <td>[Programmed cell death (PCD) is the regulated ...</td>\n",
       "      <td>Results depicted mitochondrial dynamics in viv...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16418930</th>\n",
       "      <td>Landolt C and snellen e acuity: differences in...</td>\n",
       "      <td>[Assessment of visual acuity depends on the op...</td>\n",
       "      <td>Using the charts described, there was only a s...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488747</th>\n",
       "      <td>Syncope during bathing in infants, a pediatric...</td>\n",
       "      <td>[Apparent life-threatening events in infants a...</td>\n",
       "      <td>\"Aquagenic maladies\" could be a pediatric form...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17208539</th>\n",
       "      <td>Are the long-term results of the transanal pul...</td>\n",
       "      <td>[The transanal endorectal pull-through (TERPT)...</td>\n",
       "      <td>Our long-term study showed significantly bette...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10808977</th>\n",
       "      <td>Can tailored interventions increase mammograph...</td>\n",
       "      <td>[Telephone counseling and tailored print commu...</td>\n",
       "      <td>The effects of the intervention were most pron...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   question  \\\n",
       "21645374  Do mitochondria play a role in remodelling lac...   \n",
       "16418930  Landolt C and snellen e acuity: differences in...   \n",
       "9488747   Syncope during bathing in infants, a pediatric...   \n",
       "17208539  Are the long-term results of the transanal pul...   \n",
       "10808977  Can tailored interventions increase mammograph...   \n",
       "\n",
       "                                                    context  \\\n",
       "21645374  [Programmed cell death (PCD) is the regulated ...   \n",
       "16418930  [Assessment of visual acuity depends on the op...   \n",
       "9488747   [Apparent life-threatening events in infants a...   \n",
       "17208539  [The transanal endorectal pull-through (TERPT)...   \n",
       "10808977  [Telephone counseling and tailored print commu...   \n",
       "\n",
       "                                                long_answer final_answer  \n",
       "21645374  Results depicted mitochondrial dynamics in viv...          yes  \n",
       "16418930  Using the charts described, there was only a s...           no  \n",
       "9488747   \"Aquagenic maladies\" could be a pediatric form...          yes  \n",
       "17208539  Our long-term study showed significantly bette...           no  \n",
       "10808977  The effects of the intervention were most pron...          yes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"/Users/casey/Documents/GitHub/LLM_Healthcare/ori_pqal.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Transform the dictionary into a DataFrame with the desired columns\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.rename(columns={\n",
    "    'QUESTION': 'question',\n",
    "    'CONTEXTS': 'context',\n",
    "    'LONG_ANSWER': 'long_answer',\n",
    "    'final_decision': 'final_answer'  # Assuming 'final_decision' corresponds to 'final_answer'\n",
    "})\n",
    "df = df[['question', 'context', 'long_answer', 'final_answer']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean & Normalize Biomedical Text\n",
    "\n",
    "We will handle things like:\n",
    "- Lowercasing (if using uncased model)\n",
    "- Removing excessive whitespace\n",
    "\t•\tOptional: Abbreviation expansion (with domain dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):  # Ensure the input is a string\n",
    "        text = text.lower().strip()\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "    return text  # Return the original value if it's not a string\n",
    "\n",
    "for col in ['question', 'context', 'long_answer']:\n",
    "    df[col] = df[col].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Labels to Integers\n",
    "\n",
    "We’ll map yes / no / maybe -> 0 / 1 / 2 for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'yes': 0, 'no': 1, 'maybe': 2}\n",
    "df['label'] = df['final_answer'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize with PubMedBERT / BioBERT\n",
    "\n",
    "Using Hugging Face’s transformers to tokenize the input pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Choose the model\n",
    "MODEL_NAME = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        str(example['question']),\n",
    "        str(example['context']),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424138c965db47dbb7bc5106b1aa10cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Created dataset and tokenize without batching\n",
    "dataset = Dataset.from_pandas(df[['question', 'context', 'label']])\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Hugging Face Dataset\n",
    "\n",
    "Convert the cleaned DataFrame into the datasets format and tokenize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71abd9b74b804db78f6c0e2696dbd2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Batched tokenization (faster)\n",
    "def tokenize_batch_function(examples):\n",
    "    questions = [str(q) for q in examples['question']]\n",
    "    contexts = [str(c) for c in examples['context']]\n",
    "    \n",
    "    return tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "# Dataset and tokenize with batching\n",
    "dataset = Dataset.from_pandas(df[['question', 'context', 'label']])\n",
    "tokenized_dataset_batched = dataset.map(tokenize_batch_function, batched=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
