{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f20235d9d1094da0837d5710d2ffb137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1326f70a75d04aacb5e963e0c68ead95",
              "IPY_MODEL_30f8f7a2acd34911b6c5d23c1b17861a",
              "IPY_MODEL_b0576b48039c4becb61ceddbb6a6c239"
            ],
            "layout": "IPY_MODEL_eed81a66af304ddf8f90988dbffab156"
          }
        },
        "1326f70a75d04aacb5e963e0c68ead95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26a3c12383c54d968ea64b8c2ff81a61",
            "placeholder": "​",
            "style": "IPY_MODEL_e4cd0e58c7644ec6aa136f588b130a6a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "30f8f7a2acd34911b6c5d23c1b17861a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3739dafa8bcd425f8c75b79d09c827e7",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5de7b9edff847479ca3a5757346f9bc",
            "value": 3
          }
        },
        "b0576b48039c4becb61ceddbb6a6c239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04cc0549ab0b492ebfb8a7a9f2a20da4",
            "placeholder": "​",
            "style": "IPY_MODEL_4e15ed056641421284fdacb48a35c664",
            "value": " 3/3 [00:07&lt;00:00,  2.48s/it]"
          }
        },
        "eed81a66af304ddf8f90988dbffab156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26a3c12383c54d968ea64b8c2ff81a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4cd0e58c7644ec6aa136f588b130a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3739dafa8bcd425f8c75b79d09c827e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5de7b9edff847479ca3a5757346f9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04cc0549ab0b492ebfb8a7a9f2a20da4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e15ed056641421284fdacb48a35c664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc93b84706a6423797dfd6be1d2b36b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bef2f8edc00f4078a8f86437d77390ec",
              "IPY_MODEL_3b821ab4b5854b7ab3404a4053afd120",
              "IPY_MODEL_18e4057ac0b049ea9fb7b26bd600fe32"
            ],
            "layout": "IPY_MODEL_a059467fcc93499fb3fff451a5131bdc"
          }
        },
        "bef2f8edc00f4078a8f86437d77390ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e85ff2c44d640aebc72c4a0f63c51f7",
            "placeholder": "​",
            "style": "IPY_MODEL_51c57fc190464aa6a400d7037af612e7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3b821ab4b5854b7ab3404a4053afd120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c13f2fbe68849a1826b5aedb9abb0ae",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b259181d23e944f9a2204e943f2ed60e",
            "value": 3
          }
        },
        "18e4057ac0b049ea9fb7b26bd600fe32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfcbec37320c4053a773eb8840fa24d5",
            "placeholder": "​",
            "style": "IPY_MODEL_1ec147fe2fbb455ea4af240d99627f19",
            "value": " 3/3 [00:09&lt;00:00,  2.97s/it]"
          }
        },
        "a059467fcc93499fb3fff451a5131bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e85ff2c44d640aebc72c4a0f63c51f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c57fc190464aa6a400d7037af612e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c13f2fbe68849a1826b5aedb9abb0ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b259181d23e944f9a2204e943f2ed60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfcbec37320c4053a773eb8840fa24d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ec147fe2fbb455ea4af240d99627f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTQ3FQxBsbWL",
        "outputId": "689fc4bf-13f6-44c1-c74c-2ec33dac2ce8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers==4.36.0\n",
        "!pip install peft==0.7.1\n",
        "!pip install datasets==2.14.0\n",
        "!pip install accelerate==0.25.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL6FGewjsjN5",
        "outputId": "33079366-5021-460f-96ae-2c12b4767d4c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers==4.36.0 in /usr/local/lib/python3.12/dist-packages (4.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.36.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.36.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.36.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.36.0) (2025.8.3)\n",
            "Requirement already satisfied: peft==0.7.1 in /usr/local/lib/python3.12/dist-packages (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (4.36.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (0.25.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (0.6.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (0.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.7.1) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.7.1) (0.15.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.7.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft==0.7.1) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2025.8.3)\n",
            "Requirement already satisfied: datasets==2.14.0 in /usr/local/lib/python3.12/dist-packages (2.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.11.1->datasets==2.14.0) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (3.12.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.0) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.14.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.14.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.14.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.14.0) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.14.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.14.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.14.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.0) (1.17.0)\n",
            "Requirement already satisfied: accelerate==0.25.0 in /usr/local/lib/python3.12/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (0.35.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.25.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.25.0) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.25.0) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-harmony"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odUv0osAZbH1",
        "outputId": "afff54cf-812d-474f-8df0-d6ac720022db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-harmony\n",
            "  Downloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: pydantic>=2.11.7 in /usr/local/lib/python3.12/dist-packages (from openai-harmony) (2.11.9)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->openai-harmony) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->openai-harmony) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->openai-harmony) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->openai-harmony) (0.4.1)\n",
            "Downloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai-harmony\n",
            "Successfully installed openai-harmony-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpt-oss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7LeRQI7ajc1",
        "outputId": "daeccc73-b2a3-4a7f-b9fd-22d3514bd0bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpt-oss\n",
            "  Downloading gpt_oss-0.0.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: openai-harmony in /usr/local/lib/python3.12/dist-packages (from gpt-oss) (0.0.4)\n",
            "Requirement already satisfied: tiktoken>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from gpt-oss) (0.11.0)\n",
            "Requirement already satisfied: aiohttp>=3.12.14 in /usr/local/lib/python3.12/dist-packages (from gpt-oss) (3.12.15)\n",
            "Collecting chz>=0.3.0 (from gpt-oss)\n",
            "  Downloading chz-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting docker>=7.1.0 (from gpt-oss)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: fastapi>=0.116.1 in /usr/local/lib/python3.12/dist-packages (from gpt-oss) (0.116.2)\n",
            "Collecting html2text>=2025.4.15 (from gpt-oss)\n",
            "  Downloading html2text-2025.4.15-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: lxml>=4.9.4 in /usr/local/lib/python3.12/dist-packages (from gpt-oss) (5.4.0)\n",
            "Requirement already satisfied: pydantic>=2.11.7 in /usr/local/lib/python3.12/dist-packages (from gpt-oss) (2.11.9)\n",
            "Collecting structlog>=25.4.0 (from gpt-oss)\n",
            "  Downloading structlog-25.4.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting tenacity>=9.1.2 (from gpt-oss)\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: uvicorn>=0.35.0 in /usr/local/lib/python3.12/dist-packages (from gpt-oss) (0.35.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from gpt-oss) (2.32.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from gpt-oss) (3.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.14->gpt-oss) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.14->gpt-oss) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.14->gpt-oss) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.14->gpt-oss) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.14->gpt-oss) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.14->gpt-oss) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.14->gpt-oss) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from chz>=0.3.0->gpt-oss) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker>=7.1.0->gpt-oss) (2.5.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.116.1->gpt-oss) (0.48.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->gpt-oss) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->gpt-oss) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->gpt-oss) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->gpt-oss) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->gpt-oss) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->gpt-oss) (2025.8.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.9.0->gpt-oss) (2024.11.6)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.35.0->gpt-oss) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.35.0->gpt-oss) (0.16.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi>=0.116.1->gpt-oss) (4.10.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi>=0.116.1->gpt-oss) (1.3.1)\n",
            "Downloading gpt_oss-0.0.7-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.0/102.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chz-0.3.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading html2text-2025.4.15-py3-none-any.whl (34 kB)\n",
            "Downloading structlog-25.4.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: tenacity, structlog, html2text, chz, docker, gpt-oss\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 8.5.0\n",
            "    Uninstalling tenacity-8.5.0:\n",
            "      Successfully uninstalled tenacity-8.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.14.1 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chz-0.3.0 docker-7.1.0 gpt-oss-0.0.7 html2text-2025.4.15 structlog-25.4.0 tenacity-9.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script_content = '''\n",
        "import argparse\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig, TaskType, get_peft_model\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    set_seed,\n",
        ")\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class ModelArguments:\n",
        "    model_name_or_path: str = field(default=\"microsoft/DialoGPT-medium\")\n",
        "    trust_remote_code: bool = field(default=True)\n",
        "\n",
        "@dataclass\n",
        "class DataArguments:\n",
        "    pubmedqa_path: str = field(default=\"pubmedqa_train.jsonl\")\n",
        "    medmcqa_path: str = field(default=\"medmcqa_train.jsonl\")\n",
        "    medqa_path: str = field(default=\"medqa_train.jsonl\")\n",
        "    max_seq_length: int = field(default=512)\n",
        "\n",
        "@dataclass\n",
        "class LoraArguments:\n",
        "    lora_rank: int = field(default=8)\n",
        "    lora_alpha: int = field(default=16)\n",
        "    lora_dropout: float = field(default=0.1)\n",
        "    target_modules: List[str] = field(default_factory=list)\n",
        "\n",
        "class InstructionDataset:\n",
        "    def __init__(self, data_path: str, tokenizer, max_length: int = 512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.data = self.load_data(data_path)\n",
        "\n",
        "    def load_data(self, data_path: str) -> List[Dict]:\n",
        "        data = []\n",
        "        try:\n",
        "            with open(data_path, 'r', encoding='utf-8') as f:\n",
        "                for line in f:\n",
        "                    data.append(json.loads(line.strip()))\n",
        "            logger.info(f\" Loaded {len(data)} examples from {data_path}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\" Error loading {data_path}: {e}\")\n",
        "            raise\n",
        "        return data\n",
        "\n",
        "    def format_instruction(self, example: Dict) -> str:\n",
        "        instruction = example.get(\"instruction\", \"\")\n",
        "        input_text = example.get(\"input\", \"\")\n",
        "        output = example.get(\"output\", \"\")\n",
        "\n",
        "\n",
        "        text = f\"{instruction} {input_text} {output}\".strip()\n",
        "        return text\n",
        "\n",
        "    def tokenize_function(self, examples):\n",
        "        formatted_texts = [self.format_instruction(ex) for ex in examples]\n",
        "\n",
        "\n",
        "        model_inputs = self.tokenizer(\n",
        "            formatted_texts,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=None,\n",
        "            add_special_tokens=True,\n",
        "        )\n",
        "\n",
        "\n",
        "        model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
        "        return model_inputs\n",
        "\n",
        "    def get_dataset(self) -> Dataset:\n",
        "        dataset = Dataset.from_list(self.data)\n",
        "        tokenized_dataset = dataset.map(\n",
        "            lambda examples: self.tokenize_function([examples]),\n",
        "            batched=False,\n",
        "            remove_columns=dataset.column_names,\n",
        "            desc=\"Tokenizing dataset\",\n",
        "        )\n",
        "        return tokenized_dataset\n",
        "\n",
        "def get_target_modules(model_name: str) -> List[str]:\n",
        "\n",
        "    model_name_lower = model_name.lower()\n",
        "\n",
        "    if \"llama\" in model_name_lower:\n",
        "        return [\"q_proj\", \"v_proj\"]\n",
        "    elif \"dialogpt\" in model_name_lower or \"gpt\" in model_name_lower:\n",
        "        return [\"c_attn\"]\n",
        "    elif \"mistral\" in model_name_lower:\n",
        "        return [\"q_proj\", \"v_proj\"]\n",
        "    else:\n",
        "        return [\"q_proj\", \"v_proj\"]  # Safe default\n",
        "\n",
        "def setup_lora_config(lora_args: LoraArguments, model_name: str):\n",
        "    target_modules = get_target_modules(model_name)\n",
        "    print(f\" Using target modules: {target_modules}\")\n",
        "\n",
        "    return LoraConfig(\n",
        "        task_type=TaskType.CAUSAL_LM,\n",
        "        r=lora_args.lora_rank,\n",
        "        lora_alpha=lora_args.lora_alpha,\n",
        "        lora_dropout=lora_args.lora_dropout,\n",
        "        target_modules=target_modules,\n",
        "        bias=\"none\",\n",
        "    )\n",
        "\n",
        "def load_model_and_tokenizer(model_args: ModelArguments, lora_config: LoraConfig):\n",
        "    print(f\" Loading model: {model_args.model_name_or_path}\")\n",
        "\n",
        "\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\n",
        "            model_args.model_name_or_path,\n",
        "            trust_remote_code=model_args.trust_remote_code,\n",
        "            padding_side=\"right\",  # Important for causal LM\n",
        "            use_fast=True,  # Use fast tokenizer if available\n",
        "        )\n",
        "        print(\"Tokenizer loaded.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading tokenizer: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "    if tokenizer.pad_token is None:\n",
        "        if tokenizer.eos_token is not None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "        else:\n",
        "            tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "        print(\"Set pad token.\")\n",
        "\n",
        "    # Model with error handling.\n",
        "    try:\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_args.model_name_or_path,\n",
        "            trust_remote_code=model_args.trust_remote_code,\n",
        "            torch_dtype=torch.float32,\n",
        "            device_map=None,\n",
        "            low_cpu_mem_usage=True,\n",
        "        )\n",
        "        print(\"Base model on CPU.\")\n",
        "\n",
        "\n",
        "        if tokenizer.pad_token == '[PAD]':\n",
        "            model.resize_token_embeddings(len(tokenizer))\n",
        "            print(\" Resized token embeddings.\")\n",
        "\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            model = model.cuda()\n",
        "            print(\" Model moved to GPU.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error loading model: {e}\")\n",
        "        raise\n",
        "\n",
        "    # LoRA with error handling.\n",
        "    try:\n",
        "        model = get_peft_model(model, lora_config)\n",
        "        model.print_trainable_parameters()\n",
        "        print(\" LoRA applied.\")\n",
        "    except Exception as e:\n",
        "        print(f\" Error applying LoRA: {e}\")\n",
        "        print(\" Available attention modules:\")\n",
        "        for name, _ in model.named_modules():\n",
        "            if any(target in name.lower() for target in [\"attn\", \"proj\", \"query\", \"key\", \"value\"]):\n",
        "                print(f\"  - {name}\")\n",
        "        raise\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "class RobustDataCollator(DataCollatorForLanguageModeling):\n",
        "\n",
        "\n",
        "    def __call__(self, features):\n",
        "\n",
        "        try:\n",
        "            batch = super().__call__(features)\n",
        "\n",
        "\n",
        "            if \"input_ids\" in batch:\n",
        "                input_ids = batch[\"input_ids\"]\n",
        "                if len(input_ids.shape) != 2:\n",
        "                    print(f\"  Fixing input_ids shape: {input_ids.shape}\")\n",
        "                    batch[\"input_ids\"] = input_ids.view(-1, input_ids.shape[-1])\n",
        "\n",
        "            if \"labels\" in batch:\n",
        "                labels = batch[\"labels\"]\n",
        "                if len(labels.shape) != 2:\n",
        "                    print(f\"  Fixing labels shape: {labels.shape}\")\n",
        "                    batch[\"labels\"] = labels.view(-1, labels.shape[-1])\n",
        "\n",
        "            return batch\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Error in data collator: {e}\")\n",
        "            print(f\"Features: {[type(f) for f in features]}\")\n",
        "            raise\n",
        "\n",
        "def train_stage(stage_name: str, data_path: str, model, tokenizer, training_args: TrainingArguments, data_args: DataArguments):\n",
        "    print(f\"\\\\n Starting training stage: {stage_name}\")\n",
        "    print(f\" Data path: {data_path}\")\n",
        "    print(f\" Output directory: {training_args.output_dir}\")\n",
        "\n",
        "    # Dataset.\n",
        "    try:\n",
        "        instruction_dataset = InstructionDataset(\n",
        "            data_path=data_path,\n",
        "            tokenizer=tokenizer,\n",
        "            max_length=data_args.max_seq_length,\n",
        "        )\n",
        "        train_dataset = instruction_dataset.get_dataset()\n",
        "        print(f\" Dataset loaded with {len(train_dataset)} examples.\")\n",
        "\n",
        "\n",
        "        if len(train_dataset) > 0:\n",
        "            sample = train_dataset[0]\n",
        "            print(f\" Sample input_ids shape: {len(sample['input_ids'])}\")\n",
        "            print(f\" Sample labels shape: {len(sample['labels'])}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error loading dataset: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "    data_collator = RobustDataCollator(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=False,\n",
        "        pad_to_multiple_of=None,\n",
        "    )\n",
        "\n",
        "    # Trainer.\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    print(\"Training.\")\n",
        "\n",
        "    # Training with error handling.\n",
        "    try:\n",
        "        trainer.train()\n",
        "        print(\" Training completed!\")\n",
        "    except Exception as e:\n",
        "        print(f\" Training failed: {e}\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            sample_batch = next(iter(trainer.get_train_dataloader()))\n",
        "            print(f\" Batch info:\")\n",
        "            for key, value in sample_batch.items():\n",
        "                if hasattr(value, 'shape'):\n",
        "                    print(f\"  {key}: {value.shape}\")\n",
        "        except:\n",
        "            print(\"Could not inspect batch\")\n",
        "        raise\n",
        "\n",
        "\n",
        "    try:\n",
        "        trainer.save_model()\n",
        "        trainer.save_state()\n",
        "        tokenizer.save_pretrained(training_args.output_dir)\n",
        "        print(f\" Model saved to {training_args.output_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\" Error saving model: {e}\")\n",
        "        raise\n",
        "\n",
        "    return trainer\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Medical QA fine-tuning\")\n",
        "\n",
        "    parser.add_argument(\"--model_name_or_path\", default=\"microsoft/DialoGPT-medium\")\n",
        "    parser.add_argument(\"--pubmedqa_path\", default=\"pubmedqa_train.jsonl\")\n",
        "    parser.add_argument(\"--medmcqa_path\", default=\"medmcqa_train.jsonl\")\n",
        "    parser.add_argument(\"--medqa_path\", default=\"medqa_train.jsonl\")\n",
        "    parser.add_argument(\"--output_dir\", default=\"./checkpoints\")\n",
        "    parser.add_argument(\"--max_seq_length\", type=int, default=128)  # Reduced further\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=1)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=1)  # Start with 1\n",
        "    parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=4)\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=5e-5)\n",
        "    parser.add_argument(\"--lora_rank\", type=int, default=4)  # Reduced\n",
        "    parser.add_argument(\"--lora_alpha\", type=int, default=8)  # Reduced\n",
        "    parser.add_argument(\"--stage\", type=str, choices=[\"all\", \"1\", \"2\", \"3\"], default=\"1\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=42)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    print(\"-\"*60)\n",
        "    print(\"Medical QA Fine-tuning.\")\n",
        "    print(\"-\"*60)\n",
        "    print(f\"Model: {args.model_name_or_path}\")\n",
        "    print(f\"Stage: {args.stage}\")\n",
        "    print(f\"Batch size: {args.batch_size}\")\n",
        "    print(f\"Max sequence length: {args.max_seq_length}\")\n",
        "    print(f\"LoRA rank: {args.lora_rank}\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    set_seed(args.seed)\n",
        "\n",
        "    model_args = ModelArguments(\n",
        "        model_name_or_path=args.model_name_or_path,\n",
        "    )\n",
        "\n",
        "    data_args = DataArguments(\n",
        "        pubmedqa_path=args.pubmedqa_path,\n",
        "        medmcqa_path=args.medmcqa_path,\n",
        "        medqa_path=args.medqa_path,\n",
        "        max_seq_length=args.max_seq_length,\n",
        "    )\n",
        "\n",
        "    lora_args = LoraArguments(\n",
        "        lora_rank=args.lora_rank,\n",
        "        lora_alpha=args.lora_alpha,\n",
        "    )\n",
        "\n",
        "    lora_config = setup_lora_config(lora_args, args.model_name_or_path)\n",
        "\n",
        "\n",
        "    stages = [\n",
        "        {\"name\": \"pubmedqa\", \"data_path\": args.pubmedqa_path, \"output_dir\": os.path.join(args.output_dir, \"pubmedqa\")},\n",
        "        {\"name\": \"medmcqa\", \"data_path\": args.medmcqa_path, \"output_dir\": os.path.join(args.output_dir, \"medmcqa\")},\n",
        "        {\"name\": \"medqa\", \"data_path\": args.medqa_path, \"output_dir\": os.path.join(args.output_dir, \"medqa\")},\n",
        "    ]\n",
        "\n",
        "    if args.stage == \"all\":\n",
        "        stages_to_run = [0, 1, 2]\n",
        "    else:\n",
        "        stages_to_run = [int(args.stage) - 1]\n",
        "\n",
        "\n",
        "    model, tokenizer = load_model_and_tokenizer(model_args, lora_config)\n",
        "\n",
        "    for stage_idx in stages_to_run:\n",
        "        stage = stages[stage_idx]\n",
        "        stage_name = stage[\"name\"]\n",
        "\n",
        "        print(f\"\\\\n{'='*50}\")\n",
        "        print(f\"STAGE {stage_idx + 1}: {stage_name.upper()}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "\n",
        "        os.makedirs(stage[\"output_dir\"], exist_ok=True)\n",
        "\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=stage[\"output_dir\"],\n",
        "            num_train_epochs=args.num_epochs,\n",
        "            per_device_train_batch_size=args.batch_size,\n",
        "            gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
        "            logging_steps=5,\n",
        "            save_steps=100,\n",
        "            learning_rate=args.learning_rate,\n",
        "            weight_decay=0.01,\n",
        "            dataloader_num_workers=0,\n",
        "            remove_unused_columns=False,\n",
        "            report_to=None,\n",
        "            save_total_limit=1,\n",
        "            load_best_model_at_end=False,\n",
        "            max_steps=50,  # Limit steps for testing\n",
        "            logging_first_step=True,\n",
        "            dataloader_drop_last=True,\n",
        "        )\n",
        "\n",
        "\n",
        "        trainer = train_stage(\n",
        "            stage_name=stage_name,\n",
        "            data_path=stage[\"data_path\"],\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            training_args=training_args,\n",
        "            data_args=data_args,\n",
        "        )\n",
        "\n",
        "        print(f\" Stage {stage_idx + 1} ({stage_name}) done.\")\n",
        "        model = trainer.model\n",
        "\n",
        "    print(\"\\\\n Training completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "with open('medical_qa_robust.py', 'w') as f:\n",
        "    f.write(script_content)\n",
        "\n",
        "print(\"Created medical_qa_robust.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xNGYaLHuQdg",
        "outputId": "6fafd7d8-75f2-48cf-aae8-4d66b747d9ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created medical_qa_robust.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python medical_qa_robust.py \\\n",
        "    --model_name_or_path \"NousResearch/Llama-2-13b-chat-hf\" \\\n",
        "    --pubmedqa_path \"pubmedqa_training.jsonl\" \\\n",
        "    --num_epochs 2 \\\n",
        "    --batch_size 1 \\\n",
        "    --gradient_accumulation_steps 8 \\\n",
        "    --max_seq_length 512 \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --stage \"1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnrZ7mZ7-IQj",
        "outputId": "b06b60f4-89a2-4794-9b7b-f5fa01d6531d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "2025-09-25 05:51:07.975567: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758779467.997129   10538 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758779468.003691   10538 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758779468.020557   10538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758779468.020584   10538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758779468.020587   10538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758779468.020590   10538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "------------------------------------------------------------\n",
            "Medical QA Fine-tuning.\n",
            "------------------------------------------------------------\n",
            "Model: NousResearch/Llama-2-13b-chat-hf\n",
            "Stage: 1\n",
            "Batch size: 1\n",
            "Max sequence length: 512\n",
            "LoRA rank: 8\n",
            "------------------------------------------------------------\n",
            " Using target modules: ['q_proj', 'v_proj']\n",
            " Loading model: NousResearch/Llama-2-13b-chat-hf\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 100% 746/746 [00:00<00:00, 5.46MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:01<00:00, 417kB/s]\n",
            "added_tokens.json: 100% 21.0/21.0 [00:00<00:00, 186kB/s]\n",
            "special_tokens_map.json: 100% 435/435 [00:00<00:00, 3.93MB/s]\n",
            "Tokenizer loaded.\n",
            "config.json: 100% 608/608 [00:00<00:00, 4.44MB/s]\n",
            "model.safetensors.index.json: 33.4kB [00:00, 122MB/s]\n",
            "Downloading shards:   0% 0/3 [00:00<?, ?it/s]\n",
            "model-00001-of-00003.safetensors:   0% 0.00/9.95G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   0% 106k/9.95G [00:01<47:25:49, 58.3kB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   6% 553M/9.95G [00:02<00:36, 256MB/s]    \u001b[A\n",
            "model-00001-of-00003.safetensors:  14% 1.37G/9.95G [00:02<00:11, 733MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 1.74G/9.95G [00:04<00:22, 372MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 1.95G/9.95G [00:05<00:23, 341MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  21% 2.11G/9.95G [00:05<00:20, 377MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 2.22G/9.95G [00:07<00:30, 254MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  24% 2.38G/9.95G [00:07<00:31, 243MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  25% 2.51G/9.95G [00:08<00:28, 258MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  26% 2.58G/9.95G [00:08<00:30, 241MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  26% 2.63G/9.95G [00:08<00:29, 248MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 2.70G/9.95G [00:09<00:27, 261MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  28% 2.78G/9.95G [00:11<01:18, 90.8MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  30% 2.99G/9.95G [00:11<00:42, 164MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:  32% 3.16G/9.95G [00:12<00:27, 243MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 3.29G/9.95G [00:12<00:21, 313MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  34% 3.39G/9.95G [00:12<00:20, 315MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 3.50G/9.95G [00:15<01:09, 92.5MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  37% 3.65G/9.95G [00:16<00:45, 138MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:  38% 3.77G/9.95G [00:16<00:34, 180MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 3.89G/9.95G [00:16<00:30, 202MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  40% 4.02G/9.95G [00:16<00:24, 242MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  42% 4.17G/9.95G [00:17<00:19, 297MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 4.24G/9.95G [00:17<00:18, 312MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 4.31G/9.95G [00:17<00:16, 336MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  44% 4.38G/9.95G [00:17<00:15, 360MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 4.48G/9.95G [00:21<01:19, 68.8MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 4.52G/9.95G [00:22<01:27, 61.9MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  46% 4.63G/9.95G [00:22<00:58, 90.7MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  47% 4.68G/9.95G [00:23<00:49, 106MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:  48% 4.77G/9.95G [00:23<00:36, 140MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 4.83G/9.95G [00:23<00:29, 175MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 4.90G/9.95G [00:23<00:24, 208MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 4.97G/9.95G [00:23<00:21, 237MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  51% 5.03G/9.95G [00:23<00:18, 266MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  51% 5.10G/9.95G [00:24<00:16, 291MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 5.17G/9.95G [00:24<00:16, 287MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 5.23G/9.95G [00:24<00:14, 336MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 5.30G/9.95G [00:24<00:14, 328MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  54% 5.38G/9.95G [00:24<00:12, 357MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 5.43G/9.95G [00:24<00:12, 363MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 5.48G/9.95G [00:25<00:12, 368MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 5.55G/9.95G [00:25<00:11, 388MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 5.60G/9.95G [00:25<00:11, 383MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 5.67G/9.95G [00:25<00:11, 387MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  58% 5.74G/9.95G [00:25<00:10, 386MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  58% 5.78G/9.95G [00:25<00:11, 357MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  59% 5.83G/9.95G [00:26<00:12, 332MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 5.92G/9.95G [00:26<00:16, 244MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 5.97G/9.95G [00:26<00:17, 233MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  61% 6.02G/9.95G [00:27<00:19, 199MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  62% 6.15G/9.95G [00:27<00:11, 328MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  62% 6.20G/9.95G [00:27<00:16, 231MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 6.25G/9.95G [00:27<00:16, 231MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 6.31G/9.95G [00:28<00:14, 252MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  64% 6.36G/9.95G [00:30<00:48, 74.3MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  64% 6.40G/9.95G [00:37<02:59, 19.8MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 6.50G/9.95G [00:37<01:41, 34.1MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 6.54G/9.95G [00:37<01:22, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 6.57G/9.95G [00:37<01:05, 51.4MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 6.72G/9.95G [00:37<00:30, 107MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 6.84G/9.95G [00:37<00:18, 167MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  70% 6.98G/9.95G [00:38<00:11, 256MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 7.17G/9.95G [00:38<00:07, 397MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  74% 7.36G/9.95G [00:38<00:04, 546MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 7.50G/9.95G [00:38<00:03, 663MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 7.68G/9.95G [00:38<00:02, 776MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  79% 7.81G/9.95G [00:38<00:03, 706MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 7.95G/9.95G [00:39<00:03, 618MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  81% 8.03G/9.95G [00:39<00:02, 656MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  82% 8.14G/9.95G [00:39<00:03, 602MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 8.25G/9.95G [00:39<00:04, 389MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  84% 8.35G/9.95G [00:40<00:04, 393MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 8.41G/9.95G [00:40<00:03, 420MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 8.47G/9.95G [00:41<00:08, 176MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  86% 8.55G/9.95G [00:42<00:10, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  86% 8.61G/9.95G [00:43<00:12, 105MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 8.63G/9.95G [00:43<00:15, 86.7MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 8.69G/9.95G [00:44<00:13, 93.1MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 8.74G/9.95G [00:44<00:12, 97.9MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 8.80G/9.95G [00:45<00:11, 97.3MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 8.87G/9.95G [00:45<00:08, 129MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:  90% 9.00G/9.95G [00:46<00:04, 196MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  91% 9.06G/9.95G [00:46<00:04, 217MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 9.11G/9.95G [00:46<00:03, 231MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 9.18G/9.95G [00:46<00:02, 286MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  94% 9.31G/9.95G [00:46<00:01, 431MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 9.47G/9.95G [00:46<00:00, 616MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  96% 9.58G/9.95G [00:46<00:00, 608MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  98% 9.72G/9.95G [00:47<00:00, 605MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  98% 9.80G/9.95G [00:47<00:00, 641MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors: 100% 9.95G/9.95G [00:47<00:00, 209MB/s]\n",
            "Downloading shards:  33% 1/3 [00:48<01:36, 48.17s/it]\n",
            "model-00002-of-00003.safetensors:   0% 0.00/9.90G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   0% 36.5k/9.90G [00:01<108:09:01, 25.4kB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 266M/9.90G [00:02<01:12, 133MB/s]      \u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 324M/9.90G [00:02<01:07, 142MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   5% 458M/9.90G [00:03<00:45, 208MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   5% 492M/9.90G [00:03<00:44, 213MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 581M/9.90G [00:03<00:39, 235MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 636M/9.90G [00:03<00:40, 228MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   7% 703M/9.90G [00:04<00:40, 224MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   8% 770M/9.90G [00:04<00:39, 230MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 844M/9.90G [00:04<00:41, 218MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 893M/9.90G [00:04<00:42, 213MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 915M/9.90G [00:05<00:47, 190MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 937M/9.90G [00:05<00:51, 173MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 973M/9.90G [00:05<00:58, 152MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 1.03G/9.90G [00:05<00:55, 159MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  11% 1.08G/9.90G [00:06<01:00, 145MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  11% 1.12G/9.90G [00:06<00:57, 153MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 1.16G/9.90G [00:06<00:55, 158MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 1.23G/9.90G [00:07<01:04, 135MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  13% 1.29G/9.90G [00:07<00:45, 190MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  14% 1.34G/9.90G [00:07<00:41, 204MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  14% 1.41G/9.90G [00:08<00:50, 168MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  15% 1.48G/9.90G [00:08<00:52, 161MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  16% 1.54G/9.90G [00:09<00:50, 165MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  16% 1.56G/9.90G [00:09<00:53, 156MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  16% 1.63G/9.90G [00:09<00:38, 217MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  17% 1.70G/9.90G [00:10<01:12, 112MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  18% 1.77G/9.90G [00:11<01:14, 109MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  19% 1.84G/9.90G [00:11<01:03, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  20% 1.97G/9.90G [00:12<01:00, 131MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 2.20G/9.90G [00:12<00:30, 249MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  23% 2.30G/9.90G [00:13<00:29, 255MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 2.37G/9.90G [00:13<00:28, 264MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 2.42G/9.90G [00:13<00:27, 272MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 2.49G/9.90G [00:13<00:27, 273MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 2.53G/9.90G [00:13<00:29, 253MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 2.58G/9.90G [00:14<00:30, 238MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  27% 2.68G/9.90G [00:14<00:25, 278MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  28% 2.77G/9.90G [00:15<00:32, 220MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 2.84G/9.90G [00:15<00:32, 215MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 2.88G/9.90G [00:15<00:33, 212MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  30% 2.93G/9.90G [00:16<00:42, 165MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  30% 3.00G/9.90G [00:16<00:42, 162MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 3.03G/9.90G [00:16<00:51, 132MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 3.06G/9.90G [00:17<01:02, 110MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 3.07G/9.90G [00:17<01:08, 100MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 3.21G/9.90G [00:17<00:30, 219MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  34% 3.41G/9.90G [00:18<00:27, 239MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  35% 3.47G/9.90G [00:18<00:27, 236MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 3.55G/9.90G [00:19<00:29, 219MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 3.60G/9.90G [00:19<00:26, 235MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  37% 3.65G/9.90G [00:21<01:19, 78.2MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  37% 3.69G/9.90G [00:21<01:06, 92.8MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  39% 3.83G/9.90G [00:21<00:36, 168MB/s] \u001b[A\n",
            "model-00002-of-00003.safetensors:  40% 3.93G/9.90G [00:22<00:26, 225MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 4.18G/9.90G [00:22<00:13, 420MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 4.29G/9.90G [00:23<00:24, 227MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  44% 4.36G/9.90G [00:23<00:27, 200MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 4.42G/9.90G [00:24<00:30, 177MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 4.47G/9.90G [00:24<00:30, 177MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 4.51G/9.90G [00:24<00:29, 180MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 4.57G/9.90G [00:25<00:28, 186MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 4.63G/9.90G [00:25<00:27, 189MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 4.70G/9.90G [00:25<00:27, 193MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  48% 4.78G/9.90G [00:25<00:20, 255MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 4.89G/9.90G [00:26<00:24, 208MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  50% 4.92G/9.90G [00:26<00:22, 219MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  50% 4.99G/9.90G [00:27<00:25, 190MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  51% 5.02G/9.90G [00:27<00:29, 168MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  51% 5.07G/9.90G [00:27<00:29, 164MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  52% 5.15G/9.90G [00:27<00:20, 230MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 5.22G/9.90G [00:28<00:31, 149MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 5.26G/9.90G [00:29<00:30, 150MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  54% 5.33G/9.90G [00:29<00:30, 151MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  54% 5.40G/9.90G [00:29<00:30, 147MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 5.52G/9.90G [00:30<00:18, 238MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 5.59G/9.90G [00:30<00:17, 254MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  57% 5.65G/9.90G [00:30<00:21, 195MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  58% 5.72G/9.90G [00:31<00:20, 205MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  58% 5.79G/9.90G [00:31<00:20, 197MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  59% 5.82G/9.90G [00:31<00:20, 201MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  59% 5.89G/9.90G [00:31<00:19, 207MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  60% 5.95G/9.90G [00:32<00:20, 191MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  61% 6.00G/9.90G [00:32<00:20, 186MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  61% 6.08G/9.90G [00:33<00:21, 180MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  62% 6.15G/9.90G [00:33<00:20, 180MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  62% 6.17G/9.90G [00:33<00:20, 179MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 6.21G/9.90G [00:33<00:20, 178MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 6.25G/9.90G [00:34<00:20, 178MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 6.40G/9.90G [00:34<00:14, 250MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 6.48G/9.90G [00:35<00:16, 207MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  66% 6.58G/9.90G [00:35<00:19, 170MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 6.79G/9.90G [00:37<00:24, 128MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 6.86G/9.90G [00:38<00:24, 126MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 6.88G/9.90G [00:42<01:05, 46.1MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  71% 7.04G/9.90G [00:42<00:35, 80.7MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 7.18G/9.90G [00:42<00:21, 125MB/s] \u001b[A\n",
            "model-00002-of-00003.safetensors:  74% 7.35G/9.90G [00:42<00:13, 190MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  76% 7.48G/9.90G [00:42<00:09, 250MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 7.63G/9.90G [00:43<00:07, 299MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  80% 7.89G/9.90G [00:43<00:04, 443MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  81% 8.00G/9.90G [00:44<00:05, 330MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 8.12G/9.90G [00:44<00:05, 336MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 8.19G/9.90G [00:44<00:05, 313MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 8.25G/9.90G [00:44<00:04, 331MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  84% 8.32G/9.90G [00:44<00:04, 353MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 8.39G/9.90G [00:45<00:04, 375MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 8.46G/9.90G [00:45<00:03, 394MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  86% 8.52G/9.90G [00:45<00:03, 402MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 8.59G/9.90G [00:45<00:03, 407MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 8.66G/9.90G [00:46<00:05, 211MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  88% 8.72G/9.90G [00:46<00:06, 188MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 8.79G/9.90G [00:47<00:05, 199MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 8.83G/9.90G [00:47<00:08, 133MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 8.87G/9.90G [00:49<00:15, 65.9MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 8.93G/9.90G [00:50<00:16, 60.8MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  91% 9.04G/9.90G [00:50<00:08, 106MB/s] \u001b[A\n",
            "model-00002-of-00003.safetensors:  93% 9.22G/9.90G [00:50<00:03, 201MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  95% 9.38G/9.90G [00:50<00:01, 301MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  96% 9.53G/9.90G [00:51<00:00, 408MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 9.66G/9.90G [00:51<00:00, 414MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 9.77G/9.90G [00:51<00:00, 417MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors: 100% 9.90G/9.90G [00:52<00:00, 190MB/s]\n",
            "Downloading shards:  67% 2/3 [01:40<00:50, 50.73s/it]\n",
            "model-00003-of-00003.safetensors:   0% 0.00/6.18G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   0% 980k/6.18G [00:08<14:34:35, 118kB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   1% 68.1M/6.18G [00:09<09:50, 10.3MB/s] \u001b[A\n",
            "model-00003-of-00003.safetensors:  13% 805M/6.18G [00:09<00:35, 151MB/s]  \u001b[A\n",
            "model-00003-of-00003.safetensors:  15% 941M/6.18G [00:09<00:29, 178MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  16% 1.01G/6.18G [00:10<00:26, 192MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  18% 1.14G/6.18G [00:10<00:20, 240MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  20% 1.21G/6.18G [00:10<00:19, 249MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  22% 1.34G/6.18G [00:10<00:14, 331MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  24% 1.48G/6.18G [00:10<00:12, 390MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  26% 1.61G/6.18G [00:10<00:09, 469MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  28% 1.75G/6.18G [00:10<00:07, 583MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  30% 1.88G/6.18G [00:11<00:06, 667MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  33% 2.01G/6.18G [00:14<00:34, 119MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  35% 2.15G/6.18G [00:15<00:31, 127MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  36% 2.21G/6.18G [00:18<00:59, 67.1MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  38% 2.35G/6.18G [00:18<00:39, 97.6MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  40% 2.48G/6.18G [00:18<00:26, 139MB/s] \u001b[A\n",
            "model-00003-of-00003.safetensors:  42% 2.62G/6.18G [00:18<00:18, 190MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  45% 2.75G/6.18G [00:19<00:14, 236MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  47% 2.89G/6.18G [00:19<00:12, 268MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  48% 2.95G/6.18G [00:19<00:11, 284MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  49% 3.02G/6.18G [00:19<00:10, 299MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  50% 3.09G/6.18G [00:20<00:10, 305MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  51% 3.16G/6.18G [00:20<00:09, 303MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  53% 3.29G/6.18G [00:22<00:26, 111MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  55% 3.42G/6.18G [00:22<00:16, 164MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  56% 3.49G/6.18G [00:22<00:14, 187MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  58% 3.55G/6.18G [00:23<00:12, 213MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  59% 3.62G/6.18G [00:23<00:10, 241MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  60% 3.69G/6.18G [00:23<00:09, 266MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  61% 3.76G/6.18G [00:23<00:08, 293MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  62% 3.82G/6.18G [00:23<00:07, 315MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  63% 3.89G/6.18G [00:23<00:06, 332MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  64% 3.96G/6.18G [00:24<00:06, 347MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  65% 4.02G/6.18G [00:24<00:06, 355MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  66% 4.09G/6.18G [00:24<00:05, 362MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  67% 4.16G/6.18G [00:24<00:05, 370MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  68% 4.23G/6.18G [00:24<00:05, 371MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  69% 4.29G/6.18G [00:24<00:04, 379MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  71% 4.36G/6.18G [00:25<00:06, 294MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  72% 4.43G/6.18G [00:25<00:08, 210MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  73% 4.50G/6.18G [00:26<00:06, 242MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  74% 4.56G/6.18G [00:26<00:05, 272MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  75% 4.63G/6.18G [00:26<00:05, 297MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  76% 4.70G/6.18G [00:26<00:04, 316MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  77% 4.77G/6.18G [00:26<00:04, 332MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  78% 4.83G/6.18G [00:26<00:03, 342MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  79% 4.90G/6.18G [00:27<00:03, 352MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  80% 4.97G/6.18G [00:27<00:03, 357MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  81% 5.03G/6.18G [00:27<00:04, 279MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  83% 5.10G/6.18G [00:29<00:10, 99.8MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  84% 5.17G/6.18G [00:29<00:09, 104MB/s] \u001b[A\n",
            "model-00003-of-00003.safetensors:  85% 5.23G/6.18G [00:30<00:08, 110MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  86% 5.31G/6.18G [00:30<00:06, 132MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  87% 5.38G/6.18G [00:30<00:04, 172MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  88% 5.44G/6.18G [00:31<00:03, 207MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  89% 5.51G/6.18G [00:31<00:02, 239MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  90% 5.58G/6.18G [00:31<00:02, 271MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  91% 5.64G/6.18G [00:31<00:01, 295MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  92% 5.71G/6.18G [00:31<00:01, 319MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  93% 5.78G/6.18G [00:31<00:01, 335MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  95% 5.84G/6.18G [00:32<00:00, 341MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  96% 5.91G/6.18G [00:32<00:00, 360MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  97% 5.98G/6.18G [00:32<00:00, 367MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  98% 6.04G/6.18G [00:32<00:00, 375MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  99% 6.11G/6.18G [00:32<00:00, 377MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors: 100% 6.18G/6.18G [00:32<00:00, 188MB/s]\n",
            "Downloading shards: 100% 3/3 [02:14<00:00, 44.76s/it]\n",
            "Loading checkpoint shards: 100% 3/3 [00:07<00:00,  2.55s/it]\n",
            "generation_config.json: 100% 196/196 [00:00<00:00, 1.58MB/s]\n",
            "Base model on CPU.\n",
            " Model moved to GPU.\n",
            "trainable params: 6,553,600 || all params: 13,022,417,920 || trainable%: 0.05032552357220002\n",
            " LoRA applied.\n",
            "\n",
            "==================================================\n",
            "STAGE 1: PUBMEDQA\n",
            "==================================================\n",
            "\n",
            " Starting training stage: pubmedqa\n",
            " Data path: pubmedqa_training.jsonl\n",
            " Output directory: ./checkpoints/pubmedqa\n",
            "INFO:__main__: Loaded 1000 examples from pubmedqa_training.jsonl\n",
            "Tokenizing dataset: 100% 1000/1000 [00:01<00:00, 614.89 examples/s]\n",
            " Dataset loaded with 1000 examples.\n",
            " Sample input_ids shape: 1\n",
            " Sample labels shape: 1\n",
            "Training.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/offline-run-20250925_055401-b7deffi3\u001b[0m\n",
            "  0% 0/50 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 487])\n",
            "  Fixing labels shape: torch.Size([1, 1, 487])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 510])\n",
            "  Fixing labels shape: torch.Size([1, 1, 510])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 254])\n",
            "  Fixing labels shape: torch.Size([1, 1, 254])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 507])\n",
            "  Fixing labels shape: torch.Size([1, 1, 507])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 490])\n",
            "  Fixing labels shape: torch.Size([1, 1, 490])\n",
            "{'loss': 1.8856, 'learning_rate': 4.9e-05, 'epoch': 0.01}\n",
            "  2% 1/50 [00:12<10:15, 12.56s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 486])\n",
            "  Fixing labels shape: torch.Size([1, 1, 486])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 434])\n",
            "  Fixing labels shape: torch.Size([1, 1, 434])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 347])\n",
            "  Fixing labels shape: torch.Size([1, 1, 347])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  4% 2/50 [00:24<09:38, 12.05s/it]  Fixing input_ids shape: torch.Size([1, 1, 483])\n",
            "  Fixing labels shape: torch.Size([1, 1, 483])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 364])\n",
            "  Fixing labels shape: torch.Size([1, 1, 364])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 358])\n",
            "  Fixing labels shape: torch.Size([1, 1, 358])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  6% 3/50 [00:35<09:14, 11.79s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 448])\n",
            "  Fixing labels shape: torch.Size([1, 1, 448])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 406])\n",
            "  Fixing labels shape: torch.Size([1, 1, 406])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 401])\n",
            "  Fixing labels shape: torch.Size([1, 1, 401])\n",
            "  8% 4/50 [00:47<09:03, 11.82s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 376])\n",
            "  Fixing labels shape: torch.Size([1, 1, 376])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 347])\n",
            "  Fixing labels shape: torch.Size([1, 1, 347])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 452])\n",
            "  Fixing labels shape: torch.Size([1, 1, 452])\n",
            "{'loss': 1.8046, 'learning_rate': 4.5e-05, 'epoch': 0.04}\n",
            " 10% 5/50 [00:58<08:42, 11.61s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 404])\n",
            "  Fixing labels shape: torch.Size([1, 1, 404])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 422])\n",
            "  Fixing labels shape: torch.Size([1, 1, 422])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 395])\n",
            "  Fixing labels shape: torch.Size([1, 1, 395])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 369])\n",
            "  Fixing labels shape: torch.Size([1, 1, 369])\n",
            " 12% 6/50 [01:10<08:31, 11.61s/it]  Fixing input_ids shape: torch.Size([1, 1, 489])\n",
            "  Fixing labels shape: torch.Size([1, 1, 489])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 410])\n",
            "  Fixing labels shape: torch.Size([1, 1, 410])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 491])\n",
            "  Fixing labels shape: torch.Size([1, 1, 491])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 424])\n",
            "  Fixing labels shape: torch.Size([1, 1, 424])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 14% 7/50 [01:21<08:17, 11.57s/it]  Fixing input_ids shape: torch.Size([1, 1, 277])\n",
            "  Fixing labels shape: torch.Size([1, 1, 277])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 429])\n",
            "  Fixing labels shape: torch.Size([1, 1, 429])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 485])\n",
            "  Fixing labels shape: torch.Size([1, 1, 485])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 480])\n",
            "  Fixing labels shape: torch.Size([1, 1, 480])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 16% 8/50 [01:33<08:04, 11.54s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 462])\n",
            "  Fixing labels shape: torch.Size([1, 1, 462])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 373])\n",
            "  Fixing labels shape: torch.Size([1, 1, 373])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 18% 9/50 [01:45<07:56, 11.63s/it]  Fixing input_ids shape: torch.Size([1, 1, 476])\n",
            "  Fixing labels shape: torch.Size([1, 1, 476])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 452])\n",
            "  Fixing labels shape: torch.Size([1, 1, 452])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "{'loss': 1.8987, 'learning_rate': 4e-05, 'epoch': 0.08}\n",
            " 20% 10/50 [01:57<07:52, 11.80s/it]  Fixing input_ids shape: torch.Size([1, 1, 481])\n",
            "  Fixing labels shape: torch.Size([1, 1, 481])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 372])\n",
            "  Fixing labels shape: torch.Size([1, 1, 372])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 377])\n",
            "  Fixing labels shape: torch.Size([1, 1, 377])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 22% 11/50 [02:08<07:36, 11.70s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 24% 12/50 [02:21<07:30, 11.85s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 444])\n",
            "  Fixing labels shape: torch.Size([1, 1, 444])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 26% 13/50 [02:33<07:20, 11.91s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 382])\n",
            "  Fixing labels shape: torch.Size([1, 1, 382])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 444])\n",
            "  Fixing labels shape: torch.Size([1, 1, 444])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 457])\n",
            "  Fixing labels shape: torch.Size([1, 1, 457])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 28% 14/50 [02:44<07:06, 11.85s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 389])\n",
            "  Fixing labels shape: torch.Size([1, 1, 389])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 320])\n",
            "  Fixing labels shape: torch.Size([1, 1, 320])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 467])\n",
            "  Fixing labels shape: torch.Size([1, 1, 467])\n",
            "{'loss': 1.7142, 'learning_rate': 3.5e-05, 'epoch': 0.12}\n",
            " 30% 15/50 [02:56<06:50, 11.73s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 490])\n",
            "  Fixing labels shape: torch.Size([1, 1, 490])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 492])\n",
            "  Fixing labels shape: torch.Size([1, 1, 492])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 473])\n",
            "  Fixing labels shape: torch.Size([1, 1, 473])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 493])\n",
            "  Fixing labels shape: torch.Size([1, 1, 493])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 32% 16/50 [03:08<06:43, 11.86s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 440])\n",
            "  Fixing labels shape: torch.Size([1, 1, 440])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 396])\n",
            "  Fixing labels shape: torch.Size([1, 1, 396])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 472])\n",
            "  Fixing labels shape: torch.Size([1, 1, 472])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 418])\n",
            "  Fixing labels shape: torch.Size([1, 1, 418])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 471])\n",
            "  Fixing labels shape: torch.Size([1, 1, 471])\n",
            " 34% 17/50 [03:20<06:29, 11.82s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 355])\n",
            "  Fixing labels shape: torch.Size([1, 1, 355])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 488])\n",
            "  Fixing labels shape: torch.Size([1, 1, 488])\n",
            " 36% 18/50 [03:32<06:18, 11.82s/it]  Fixing input_ids shape: torch.Size([1, 1, 373])\n",
            "  Fixing labels shape: torch.Size([1, 1, 373])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 440])\n",
            "  Fixing labels shape: torch.Size([1, 1, 440])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 393])\n",
            "  Fixing labels shape: torch.Size([1, 1, 393])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 488])\n",
            "  Fixing labels shape: torch.Size([1, 1, 488])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 38% 19/50 [03:43<06:03, 11.72s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 405])\n",
            "  Fixing labels shape: torch.Size([1, 1, 405])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 481])\n",
            "  Fixing labels shape: torch.Size([1, 1, 481])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 477])\n",
            "  Fixing labels shape: torch.Size([1, 1, 477])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "{'loss': 1.7526, 'learning_rate': 3e-05, 'epoch': 0.16}\n",
            " 40% 20/50 [03:55<05:53, 11.79s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 387])\n",
            "  Fixing labels shape: torch.Size([1, 1, 387])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 489])\n",
            "  Fixing labels shape: torch.Size([1, 1, 489])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 42% 21/50 [04:07<05:43, 11.85s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 324])\n",
            "  Fixing labels shape: torch.Size([1, 1, 324])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 44% 22/50 [04:19<05:31, 11.84s/it]  Fixing input_ids shape: torch.Size([1, 1, 383])\n",
            "  Fixing labels shape: torch.Size([1, 1, 383])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 418])\n",
            "  Fixing labels shape: torch.Size([1, 1, 418])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 328])\n",
            "  Fixing labels shape: torch.Size([1, 1, 328])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 420])\n",
            "  Fixing labels shape: torch.Size([1, 1, 420])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 493])\n",
            "  Fixing labels shape: torch.Size([1, 1, 493])\n",
            " 46% 23/50 [04:30<05:14, 11.64s/it]  Fixing input_ids shape: torch.Size([1, 1, 381])\n",
            "  Fixing labels shape: torch.Size([1, 1, 381])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 463])\n",
            "  Fixing labels shape: torch.Size([1, 1, 463])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 417])\n",
            "  Fixing labels shape: torch.Size([1, 1, 417])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 465])\n",
            "  Fixing labels shape: torch.Size([1, 1, 465])\n",
            " 48% 24/50 [04:42<05:03, 11.66s/it]  Fixing input_ids shape: torch.Size([1, 1, 438])\n",
            "  Fixing labels shape: torch.Size([1, 1, 438])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 441])\n",
            "  Fixing labels shape: torch.Size([1, 1, 441])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "{'loss': 1.6881, 'learning_rate': 2.5e-05, 'epoch': 0.2}\n",
            " 50% 25/50 [04:54<04:53, 11.73s/it]  Fixing input_ids shape: torch.Size([1, 1, 424])\n",
            "  Fixing labels shape: torch.Size([1, 1, 424])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 461])\n",
            "  Fixing labels shape: torch.Size([1, 1, 461])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 436])\n",
            "  Fixing labels shape: torch.Size([1, 1, 436])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 509])\n",
            "  Fixing labels shape: torch.Size([1, 1, 509])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 52% 26/50 [05:05<04:42, 11.79s/it]  Fixing input_ids shape: torch.Size([1, 1, 413])\n",
            "  Fixing labels shape: torch.Size([1, 1, 413])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 490])\n",
            "  Fixing labels shape: torch.Size([1, 1, 490])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 506])\n",
            "  Fixing labels shape: torch.Size([1, 1, 506])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 417])\n",
            "  Fixing labels shape: torch.Size([1, 1, 417])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 54% 27/50 [05:17<04:31, 11.81s/it]  Fixing input_ids shape: torch.Size([1, 1, 491])\n",
            "  Fixing labels shape: torch.Size([1, 1, 491])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 432])\n",
            "  Fixing labels shape: torch.Size([1, 1, 432])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 436])\n",
            "  Fixing labels shape: torch.Size([1, 1, 436])\n",
            " 56% 28/50 [05:29<04:21, 11.89s/it]  Fixing input_ids shape: torch.Size([1, 1, 423])\n",
            "  Fixing labels shape: torch.Size([1, 1, 423])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 468])\n",
            "  Fixing labels shape: torch.Size([1, 1, 468])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 477])\n",
            "  Fixing labels shape: torch.Size([1, 1, 477])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 475])\n",
            "  Fixing labels shape: torch.Size([1, 1, 475])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 471])\n",
            "  Fixing labels shape: torch.Size([1, 1, 471])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 58% 29/50 [05:41<04:09, 11.90s/it]  Fixing input_ids shape: torch.Size([1, 1, 445])\n",
            "  Fixing labels shape: torch.Size([1, 1, 445])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 464])\n",
            "  Fixing labels shape: torch.Size([1, 1, 464])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 468])\n",
            "  Fixing labels shape: torch.Size([1, 1, 468])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 498])\n",
            "  Fixing labels shape: torch.Size([1, 1, 498])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 471])\n",
            "  Fixing labels shape: torch.Size([1, 1, 471])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 459])\n",
            "  Fixing labels shape: torch.Size([1, 1, 459])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 408])\n",
            "  Fixing labels shape: torch.Size([1, 1, 408])\n",
            "{'loss': 1.7377, 'learning_rate': 2e-05, 'epoch': 0.24}\n",
            " 60% 30/50 [05:53<03:58, 11.94s/it]  Fixing input_ids shape: torch.Size([1, 1, 464])\n",
            "  Fixing labels shape: torch.Size([1, 1, 464])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 411])\n",
            "  Fixing labels shape: torch.Size([1, 1, 411])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 499])\n",
            "  Fixing labels shape: torch.Size([1, 1, 499])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 62% 31/50 [06:05<03:46, 11.89s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 499])\n",
            "  Fixing labels shape: torch.Size([1, 1, 499])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 429])\n",
            "  Fixing labels shape: torch.Size([1, 1, 429])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 64% 32/50 [06:17<03:34, 11.94s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 503])\n",
            "  Fixing labels shape: torch.Size([1, 1, 503])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 496])\n",
            "  Fixing labels shape: torch.Size([1, 1, 496])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 438])\n",
            "  Fixing labels shape: torch.Size([1, 1, 438])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 66% 33/50 [06:29<03:23, 11.98s/it]  Fixing input_ids shape: torch.Size([1, 1, 363])\n",
            "  Fixing labels shape: torch.Size([1, 1, 363])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 461])\n",
            "  Fixing labels shape: torch.Size([1, 1, 461])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 388])\n",
            "  Fixing labels shape: torch.Size([1, 1, 388])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 461])\n",
            "  Fixing labels shape: torch.Size([1, 1, 461])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 439])\n",
            "  Fixing labels shape: torch.Size([1, 1, 439])\n",
            " 68% 34/50 [06:41<03:09, 11.87s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 467])\n",
            "  Fixing labels shape: torch.Size([1, 1, 467])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "{'loss': 1.715, 'learning_rate': 1.5e-05, 'epoch': 0.28}\n",
            " 70% 35/50 [06:53<02:58, 11.92s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 403])\n",
            "  Fixing labels shape: torch.Size([1, 1, 403])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 324])\n",
            "  Fixing labels shape: torch.Size([1, 1, 324])\n",
            " 72% 36/50 [07:05<02:47, 11.94s/it]  Fixing input_ids shape: torch.Size([1, 1, 457])\n",
            "  Fixing labels shape: torch.Size([1, 1, 457])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 347])\n",
            "  Fixing labels shape: torch.Size([1, 1, 347])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 368])\n",
            "  Fixing labels shape: torch.Size([1, 1, 368])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 74% 37/50 [07:16<02:31, 11.68s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 440])\n",
            "  Fixing labels shape: torch.Size([1, 1, 440])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 477])\n",
            "  Fixing labels shape: torch.Size([1, 1, 477])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 76% 38/50 [07:28<02:21, 11.79s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 393])\n",
            "  Fixing labels shape: torch.Size([1, 1, 393])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 436])\n",
            "  Fixing labels shape: torch.Size([1, 1, 436])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 78% 39/50 [07:40<02:09, 11.81s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 485])\n",
            "  Fixing labels shape: torch.Size([1, 1, 485])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 456])\n",
            "  Fixing labels shape: torch.Size([1, 1, 456])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 367])\n",
            "  Fixing labels shape: torch.Size([1, 1, 367])\n",
            "{'loss': 1.6184, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
            " 80% 40/50 [07:52<01:59, 11.92s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 479])\n",
            "  Fixing labels shape: torch.Size([1, 1, 479])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 450])\n",
            "  Fixing labels shape: torch.Size([1, 1, 450])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 406])\n",
            "  Fixing labels shape: torch.Size([1, 1, 406])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 82% 41/50 [08:04<01:46, 11.83s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 498])\n",
            "  Fixing labels shape: torch.Size([1, 1, 498])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 393])\n",
            "  Fixing labels shape: torch.Size([1, 1, 393])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 84% 42/50 [08:16<01:34, 11.87s/it]  Fixing input_ids shape: torch.Size([1, 1, 264])\n",
            "  Fixing labels shape: torch.Size([1, 1, 264])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 384])\n",
            "  Fixing labels shape: torch.Size([1, 1, 384])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 501])\n",
            "  Fixing labels shape: torch.Size([1, 1, 501])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 314])\n",
            "  Fixing labels shape: torch.Size([1, 1, 314])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 398])\n",
            "  Fixing labels shape: torch.Size([1, 1, 398])\n",
            " 86% 43/50 [08:26<01:20, 11.53s/it]  Fixing input_ids shape: torch.Size([1, 1, 442])\n",
            "  Fixing labels shape: torch.Size([1, 1, 442])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 461])\n",
            "  Fixing labels shape: torch.Size([1, 1, 461])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 88% 44/50 [08:38<01:09, 11.62s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 338])\n",
            "  Fixing labels shape: torch.Size([1, 1, 338])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "{'loss': 1.6251, 'learning_rate': 5e-06, 'epoch': 0.36}\n",
            " 90% 45/50 [08:50<00:58, 11.68s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 400])\n",
            "  Fixing labels shape: torch.Size([1, 1, 400])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 452])\n",
            "  Fixing labels shape: torch.Size([1, 1, 452])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 379])\n",
            "  Fixing labels shape: torch.Size([1, 1, 379])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 490])\n",
            "  Fixing labels shape: torch.Size([1, 1, 490])\n",
            " 92% 46/50 [09:02<00:46, 11.66s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 417])\n",
            "  Fixing labels shape: torch.Size([1, 1, 417])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 451])\n",
            "  Fixing labels shape: torch.Size([1, 1, 451])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 508])\n",
            "  Fixing labels shape: torch.Size([1, 1, 508])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 427])\n",
            "  Fixing labels shape: torch.Size([1, 1, 427])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 399])\n",
            "  Fixing labels shape: torch.Size([1, 1, 399])\n",
            " 94% 47/50 [09:14<00:35, 11.74s/it]  Fixing input_ids shape: torch.Size([1, 1, 510])\n",
            "  Fixing labels shape: torch.Size([1, 1, 510])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 456])\n",
            "  Fixing labels shape: torch.Size([1, 1, 456])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 472])\n",
            "  Fixing labels shape: torch.Size([1, 1, 472])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 448])\n",
            "  Fixing labels shape: torch.Size([1, 1, 448])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 508])\n",
            "  Fixing labels shape: torch.Size([1, 1, 508])\n",
            " 96% 48/50 [09:25<00:23, 11.77s/it]  Fixing input_ids shape: torch.Size([1, 1, 492])\n",
            "  Fixing labels shape: torch.Size([1, 1, 492])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 480])\n",
            "  Fixing labels shape: torch.Size([1, 1, 480])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 504])\n",
            "  Fixing labels shape: torch.Size([1, 1, 504])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 493])\n",
            "  Fixing labels shape: torch.Size([1, 1, 493])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            " 98% 49/50 [09:38<00:11, 11.89s/it]  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 374])\n",
            "  Fixing labels shape: torch.Size([1, 1, 374])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 512])\n",
            "  Fixing labels shape: torch.Size([1, 1, 512])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 509])\n",
            "  Fixing labels shape: torch.Size([1, 1, 509])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 504])\n",
            "  Fixing labels shape: torch.Size([1, 1, 504])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 328])\n",
            "  Fixing labels shape: torch.Size([1, 1, 328])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 313])\n",
            "  Fixing labels shape: torch.Size([1, 1, 313])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 491])\n",
            "  Fixing labels shape: torch.Size([1, 1, 491])\n",
            "{'loss': 1.685, 'learning_rate': 0.0, 'epoch': 0.4}\n",
            "{'train_runtime': 593.3548, 'train_samples_per_second': 0.674, 'train_steps_per_second': 0.084, 'train_loss': 1.7255658435821533, 'epoch': 0.4}\n",
            "100% 50/50 [09:48<00:00, 11.78s/it]\n",
            " Training completed!\n",
            " Model saved to ./checkpoints/pubmedqa\n",
            " Stage 1 (pubmedqa) done.\n",
            "\n",
            " Training completed.\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20250925_055401-b7deffi3\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250925_055401-b7deffi3/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "# Loading the fine-tuned model.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./checkpoints/pubmedqa\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"NousResearch/Llama-2-13b-chat-hf\")\n",
        "model = PeftModel.from_pretrained(base_model, \"./checkpoints/pubmedqa\")\n",
        "\n",
        "\n",
        "prompt = \"Question: What is the normal body temperature? Answer:\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs, max_new_tokens=50)\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337,
          "referenced_widgets": [
            "f20235d9d1094da0837d5710d2ffb137",
            "1326f70a75d04aacb5e963e0c68ead95",
            "30f8f7a2acd34911b6c5d23c1b17861a",
            "b0576b48039c4becb61ceddbb6a6c239",
            "eed81a66af304ddf8f90988dbffab156",
            "26a3c12383c54d968ea64b8c2ff81a61",
            "e4cd0e58c7644ec6aa136f588b130a6a",
            "3739dafa8bcd425f8c75b79d09c827e7",
            "b5de7b9edff847479ca3a5757346f9bc",
            "04cc0549ab0b492ebfb8a7a9f2a20da4",
            "4e15ed056641421284fdacb48a35c664"
          ]
        },
        "id": "VL28CulTu0Bj",
        "outputId": "4c18ce51-c41d-40c1-facd-065f24ee99cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f20235d9d1094da0837d5710d2ffb137"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the normal body temperature? Answer: The normal body temperature is around 98.6 degrees Fahrenheit (37 degrees Celsius). However, it can vary depending on the time of day, age, and other factors. It is generally considered normal if the body temperature\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"./checkpoints/pubmedqa\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"NousResearch/Llama-2-13b-chat-hf\")\n",
        "model = PeftModel.from_pretrained(base_model, \"./checkpoints/pubmedqa\")\n",
        "\n",
        "\n",
        "prompt = \"Question: What are the main causes of breast cancer? Answer:\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs, max_new_tokens=50)\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "cc93b84706a6423797dfd6be1d2b36b7",
            "bef2f8edc00f4078a8f86437d77390ec",
            "3b821ab4b5854b7ab3404a4053afd120",
            "18e4057ac0b049ea9fb7b26bd600fe32",
            "a059467fcc93499fb3fff451a5131bdc",
            "0e85ff2c44d640aebc72c4a0f63c51f7",
            "51c57fc190464aa6a400d7037af612e7",
            "5c13f2fbe68849a1826b5aedb9abb0ae",
            "b259181d23e944f9a2204e943f2ed60e",
            "bfcbec37320c4053a773eb8840fa24d5",
            "1ec147fe2fbb455ea4af240d99627f19"
          ]
        },
        "id": "1un5gGPgdg_v",
        "outputId": "cb6edfe3-0758-4e31-b5fd-793cb4df26a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc93b84706a6423797dfd6be1d2b36b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the main causes of breast cancer? Answer: There are several risk factors that can increase a woman's chances of developing breast cancer. Some of the main causes of breast cancer include: 1. Genetics: Women with a family history of breast cancer are at a higher risk of\n"
          ]
        }
      ]
    }
  ]
}