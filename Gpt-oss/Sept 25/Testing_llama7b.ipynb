{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f577442da1cf447bb8a4292ce0994c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08a121c39a9947b58639654d1f803af6",
              "IPY_MODEL_74e1b1e79de240e3a5ddca74e1f25ddd",
              "IPY_MODEL_ca88690472434907bdee0d038db65466"
            ],
            "layout": "IPY_MODEL_6c2e971b2f11443db3701bc44174461e"
          }
        },
        "08a121c39a9947b58639654d1f803af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15e543c5dec64838a3452a1667854b99",
            "placeholder": "​",
            "style": "IPY_MODEL_b7feedea3f5047d392aa68643afe4ab4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "74e1b1e79de240e3a5ddca74e1f25ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3bbff1377864c94a025dcb6f7978381",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83a953d696304ab08a9f5d5c3295034d",
            "value": 2
          }
        },
        "ca88690472434907bdee0d038db65466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33053f994f6d4e2191e85d18bc3cb0ee",
            "placeholder": "​",
            "style": "IPY_MODEL_c478c9d3bb574d97a85f872da9c4690f",
            "value": " 2/2 [00:03&lt;00:00,  1.73s/it]"
          }
        },
        "6c2e971b2f11443db3701bc44174461e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15e543c5dec64838a3452a1667854b99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7feedea3f5047d392aa68643afe4ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3bbff1377864c94a025dcb6f7978381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a953d696304ab08a9f5d5c3295034d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33053f994f6d4e2191e85d18bc3cb0ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c478c9d3bb574d97a85f872da9c4690f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTQ3FQxBsbWL",
        "outputId": "3c4d4fd2-1dff-409e-c535-c70d095da9a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers==4.36.0\n",
        "!pip install peft==0.7.1\n",
        "!pip install datasets==2.14.0\n",
        "!pip install accelerate==0.25.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL6FGewjsjN5",
        "outputId": "0a9c48fc-6d17-47ac-82dd-56f69000592f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers==4.36.0 in /usr/local/lib/python3.12/dist-packages (4.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.36.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.36.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.36.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.36.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.36.0) (2025.8.3)\n",
            "Requirement already satisfied: peft==0.7.1 in /usr/local/lib/python3.12/dist-packages (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (4.36.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (0.25.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (0.6.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.7.1) (0.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.7.1) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.7.1) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.7.1) (0.15.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.7.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft==0.7.1) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2025.8.3)\n",
            "Requirement already satisfied: datasets==2.14.0 in /usr/local/lib/python3.12/dist-packages (2.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.11.1->datasets==2.14.0) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (3.12.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.0) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.0) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.14.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.14.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.14.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.14.0) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.14.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.14.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.14.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.0) (1.17.0)\n",
            "Requirement already satisfied: accelerate==0.25.0 in /usr/local/lib/python3.12/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (0.35.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.25.0) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.25.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.25.0) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.25.0) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script_content = '''\n",
        "import argparse\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig, TaskType, get_peft_model\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    set_seed,\n",
        ")\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class ModelArguments:\n",
        "    model_name_or_path: str = field(default=\"microsoft/DialoGPT-medium\")\n",
        "    trust_remote_code: bool = field(default=True)\n",
        "\n",
        "@dataclass\n",
        "class DataArguments:\n",
        "    pubmedqa_path: str = field(default=\"pubmedqa_train.jsonl\")\n",
        "    medmcqa_path: str = field(default=\"medmcqa_train.jsonl\")\n",
        "    medqa_path: str = field(default=\"medqa_train.jsonl\")\n",
        "    max_seq_length: int = field(default=512)\n",
        "\n",
        "@dataclass\n",
        "class LoraArguments:\n",
        "    lora_rank: int = field(default=8)\n",
        "    lora_alpha: int = field(default=16)\n",
        "    lora_dropout: float = field(default=0.1)\n",
        "    target_modules: List[str] = field(default_factory=list)\n",
        "\n",
        "class InstructionDataset:\n",
        "    def __init__(self, data_path: str, tokenizer, max_length: int = 512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.data = self.load_data(data_path)\n",
        "\n",
        "    def load_data(self, data_path: str) -> List[Dict]:\n",
        "        data = []\n",
        "        try:\n",
        "            with open(data_path, 'r', encoding='utf-8') as f:\n",
        "                for line in f:\n",
        "                    data.append(json.loads(line.strip()))\n",
        "            logger.info(f\"Loaded {len(data)} examples from {data_path}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading {data_path}: {e}\")\n",
        "            raise\n",
        "        return data\n",
        "\n",
        "    def format_instruction(self, example: Dict) -> str:\n",
        "        instruction = example.get(\"instruction\", \"\")\n",
        "        input_text = example.get(\"input\", \"\")\n",
        "        output = example.get(\"output\", \"\")\n",
        "\n",
        "\n",
        "        text = f\"{instruction} {input_text} {output}\".strip()\n",
        "        return text\n",
        "\n",
        "    def tokenize_function(self, examples):\n",
        "        formatted_texts = [self.format_instruction(ex) for ex in examples]\n",
        "\n",
        "\n",
        "        model_inputs = self.tokenizer(\n",
        "            formatted_texts,\n",
        "            truncation=True,\n",
        "            padding=True,  # Enable padding\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=None,\n",
        "            add_special_tokens=True,\n",
        "        )\n",
        "\n",
        "\n",
        "        model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
        "        return model_inputs\n",
        "\n",
        "    def get_dataset(self) -> Dataset:\n",
        "        dataset = Dataset.from_list(self.data)\n",
        "        tokenized_dataset = dataset.map(\n",
        "            lambda examples: self.tokenize_function([examples]),\n",
        "            batched=False,\n",
        "            remove_columns=dataset.column_names,\n",
        "            desc=\"Tokenizing dataset\",\n",
        "        )\n",
        "        return tokenized_dataset\n",
        "\n",
        "def get_target_modules(model_name: str) -> List[str]:\n",
        "    model_name_lower = model_name.lower()\n",
        "\n",
        "    if \"llama\" in model_name_lower:\n",
        "        return [\"q_proj\", \"v_proj\"]\n",
        "    elif \"dialogpt\" in model_name_lower or \"gpt\" in model_name_lower:\n",
        "        return [\"c_attn\"]\n",
        "    elif \"mistral\" in model_name_lower:\n",
        "        return [\"q_proj\", \"v_proj\"]\n",
        "    else:\n",
        "        return [\"q_proj\", \"v_proj\"]  # Safe default\n",
        "\n",
        "def setup_lora_config(lora_args: LoraArguments, model_name: str):\n",
        "    target_modules = get_target_modules(model_name)\n",
        "    print(f\"Using target modules: {target_modules}\")\n",
        "\n",
        "    return LoraConfig(\n",
        "        task_type=TaskType.CAUSAL_LM,\n",
        "        r=lora_args.lora_rank,\n",
        "        lora_alpha=lora_args.lora_alpha,\n",
        "        lora_dropout=lora_args.lora_dropout,\n",
        "        target_modules=target_modules,\n",
        "        bias=\"none\",\n",
        "    )\n",
        "\n",
        "def load_model_and_tokenizer(model_args: ModelArguments, lora_config: LoraConfig):\n",
        "    print(f\"Loading model: {model_args.model_name_or_path}\")\n",
        "\n",
        "    # Tokenizer.\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\n",
        "            model_args.model_name_or_path,\n",
        "            trust_remote_code=model_args.trust_remote_code,\n",
        "            padding_side=\"right\",  # Important for causal LM\n",
        "            use_fast=True,\n",
        "        )\n",
        "        print(\"Tokenizer loaded.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading tokenizer: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "    if tokenizer.pad_token is None:\n",
        "        if tokenizer.eos_token is not None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "        else:\n",
        "            tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "        print(\"Set pad token.\")\n",
        "\n",
        "    # Model with error handling.\n",
        "    try:\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_args.model_name_or_path,\n",
        "            trust_remote_code=model_args.trust_remote_code,\n",
        "            torch_dtype=torch.float32,\n",
        "            device_map=None,  # Load on CPU first, then move to GPU\n",
        "            low_cpu_mem_usage=True,\n",
        "        )\n",
        "        print(\"Base model loaded on CPU.\")\n",
        "\n",
        "\n",
        "        if tokenizer.pad_token == '[PAD]':\n",
        "            model.resize_token_embeddings(len(tokenizer))\n",
        "            print(\"Resized token embeddings.\")\n",
        "\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            model = model.cuda()\n",
        "            print(\"Model to GPU.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        raise\n",
        "\n",
        "    # LoRA with error handling.\n",
        "    try:\n",
        "        model = get_peft_model(model, lora_config)\n",
        "        model.print_trainable_parameters()\n",
        "        print(\"LoRA applied.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error applying LoRA: {e}\")\n",
        "        print(\"Available attention modules:\")\n",
        "        for name, _ in model.named_modules():\n",
        "            if any(target in name.lower() for target in [\"attn\", \"proj\", \"query\", \"key\", \"value\"]):\n",
        "                print(f\"  - {name}\")\n",
        "        raise\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "class RobustDataCollator(DataCollatorForLanguageModeling):\n",
        "\n",
        "\n",
        "    def __call__(self, features):\n",
        "\n",
        "        try:\n",
        "            batch = super().__call__(features)\n",
        "\n",
        "\n",
        "            if \"input_ids\" in batch:\n",
        "                input_ids = batch[\"input_ids\"]\n",
        "                if len(input_ids.shape) != 2:\n",
        "                    print(f\"  Fixing input_ids shape: {input_ids.shape}\")\n",
        "                    batch[\"input_ids\"] = input_ids.view(-1, input_ids.shape[-1])\n",
        "\n",
        "            if \"labels\" in batch:\n",
        "                labels = batch[\"labels\"]\n",
        "                if len(labels.shape) != 2:\n",
        "                    print(f\"  Fixing labels shape: {labels.shape}\")\n",
        "                    batch[\"labels\"] = labels.view(-1, labels.shape[-1])\n",
        "\n",
        "            return batch\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Error in data collator: {e}\")\n",
        "            print(f\"Features: {[type(f) for f in features]}\")\n",
        "            raise\n",
        "\n",
        "def train_stage(stage_name: str, data_path: str, model, tokenizer, training_args: TrainingArguments, data_args: DataArguments):\n",
        "    print(f\"\\\\n Starting training stage: {stage_name}\")\n",
        "    print(f\" Data path: {data_path}\")\n",
        "    print(f\" Output directory: {training_args.output_dir}\")\n",
        "\n",
        "    # Dataset.\n",
        "    try:\n",
        "        instruction_dataset = InstructionDataset(\n",
        "            data_path=data_path,\n",
        "            tokenizer=tokenizer,\n",
        "            max_length=data_args.max_seq_length,\n",
        "        )\n",
        "        train_dataset = instruction_dataset.get_dataset()\n",
        "        print(f\" Dataset loaded with {len(train_dataset)} examples.\")\n",
        "\n",
        "\n",
        "        if len(train_dataset) > 0:\n",
        "            sample = train_dataset[0]\n",
        "            print(f\" Sample input_ids shape: {len(sample['input_ids'])}\")\n",
        "            print(f\" Sample labels shape: {len(sample['labels'])}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error loading dataset: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "    data_collator = RobustDataCollator(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=False,\n",
        "        pad_to_multiple_of=None,\n",
        "    )\n",
        "\n",
        "    # Trainer.\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    print(\"Training.\")\n",
        "\n",
        "    # Training with error handling.\n",
        "    try:\n",
        "        trainer.train()\n",
        "        print(\"Training done.\")\n",
        "    except Exception as e:\n",
        "        print(f\" Training failed: {e}\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            sample_batch = next(iter(trainer.get_train_dataloader()))\n",
        "            print(f\" Batch info:\")\n",
        "            for key, value in sample_batch.items():\n",
        "                if hasattr(value, 'shape'):\n",
        "                    print(f\"  {key}: {value.shape}\")\n",
        "        except:\n",
        "            print(\"Could not inspect batch\")\n",
        "        raise\n",
        "\n",
        "\n",
        "    try:\n",
        "        trainer.save_model()\n",
        "        trainer.save_state()\n",
        "        tokenizer.save_pretrained(training_args.output_dir)\n",
        "        print(f\" Model saved to {training_args.output_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\" Error saving model: {e}\")\n",
        "        raise\n",
        "\n",
        "    return trainer\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Medical QA fine-tuning\")\n",
        "\n",
        "    parser.add_argument(\"--model_name_or_path\", default=\"microsoft/DialoGPT-medium\")\n",
        "    parser.add_argument(\"--pubmedqa_path\", default=\"pubmedqa_train.jsonl\")\n",
        "    parser.add_argument(\"--medmcqa_path\", default=\"medmcqa_train.jsonl\")\n",
        "    parser.add_argument(\"--medqa_path\", default=\"medqa_train.jsonl\")\n",
        "    parser.add_argument(\"--output_dir\", default=\"./checkpoints\")\n",
        "    parser.add_argument(\"--max_seq_length\", type=int, default=128)  # Reduced further\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=1)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=1)  # Start with 1\n",
        "    parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=4)\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=5e-5)\n",
        "    parser.add_argument(\"--lora_rank\", type=int, default=4)  # Reduced\n",
        "    parser.add_argument(\"--lora_alpha\", type=int, default=8)  # Reduced\n",
        "    parser.add_argument(\"--stage\", type=str, choices=[\"all\", \"1\", \"2\", \"3\"], default=\"1\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=42)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    print(\"-\"*60)\n",
        "    print(\"Medical QA Fine-Tuning.\")\n",
        "    print(\"-\"*60)\n",
        "    print(f\"Model: {args.model_name_or_path}\")\n",
        "    print(f\"Stage: {args.stage}\")\n",
        "    print(f\"Batch size: {args.batch_size}\")\n",
        "    print(f\"Max sequence length: {args.max_seq_length}\")\n",
        "    print(f\"LoRA rank: {args.lora_rank}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    set_seed(args.seed)\n",
        "\n",
        "    model_args = ModelArguments(\n",
        "        model_name_or_path=args.model_name_or_path,\n",
        "    )\n",
        "\n",
        "    data_args = DataArguments(\n",
        "        pubmedqa_path=args.pubmedqa_path,\n",
        "        medmcqa_path=args.medmcqa_path,\n",
        "        medqa_path=args.medqa_path,\n",
        "        max_seq_length=args.max_seq_length,\n",
        "    )\n",
        "\n",
        "    lora_args = LoraArguments(\n",
        "        lora_rank=args.lora_rank,\n",
        "        lora_alpha=args.lora_alpha,\n",
        "    )\n",
        "\n",
        "    lora_config = setup_lora_config(lora_args, args.model_name_or_path)\n",
        "\n",
        "\n",
        "    stages = [\n",
        "        {\"name\": \"pubmedqa\", \"data_path\": args.pubmedqa_path, \"output_dir\": os.path.join(args.output_dir, \"pubmedqa\")},\n",
        "        {\"name\": \"medmcqa\", \"data_path\": args.medmcqa_path, \"output_dir\": os.path.join(args.output_dir, \"medmcqa\")},\n",
        "        {\"name\": \"medqa\", \"data_path\": args.medqa_path, \"output_dir\": os.path.join(args.output_dir, \"medqa\")},\n",
        "    ]\n",
        "\n",
        "    if args.stage == \"all\":\n",
        "        stages_to_run = [0, 1, 2]\n",
        "    else:\n",
        "        stages_to_run = [int(args.stage) - 1]\n",
        "\n",
        "\n",
        "    model, tokenizer = load_model_and_tokenizer(model_args, lora_config)\n",
        "\n",
        "    for stage_idx in stages_to_run:\n",
        "        stage = stages[stage_idx]\n",
        "        stage_name = stage[\"name\"]\n",
        "\n",
        "        print(f\"\\\\n{'='*50}\")\n",
        "        print(f\"STAGE {stage_idx + 1}: {stage_name.upper()}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "\n",
        "        os.makedirs(stage[\"output_dir\"], exist_ok=True)\n",
        "\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=stage[\"output_dir\"],\n",
        "            num_train_epochs=args.num_epochs,\n",
        "            per_device_train_batch_size=args.batch_size,\n",
        "            gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
        "            logging_steps=5,\n",
        "            save_steps=100,\n",
        "            learning_rate=args.learning_rate,\n",
        "            weight_decay=0.01,\n",
        "            dataloader_num_workers=0,\n",
        "            remove_unused_columns=False,\n",
        "            report_to=None,\n",
        "            save_total_limit=1,\n",
        "            load_best_model_at_end=False,\n",
        "            max_steps=50,  # Limit steps for testing\n",
        "            logging_first_step=True,\n",
        "            dataloader_drop_last=True,  # Drop incomplete batches\n",
        "        )\n",
        "\n",
        "\n",
        "        trainer = train_stage(\n",
        "            stage_name=stage_name,\n",
        "            data_path=stage[\"data_path\"],\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            training_args=training_args,\n",
        "            data_args=data_args,\n",
        "        )\n",
        "\n",
        "        print(f\" Stage {stage_idx + 1} ({stage_name}) completed!\")\n",
        "        model = trainer.model\n",
        "\n",
        "    print(\"\\\\n Training done.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "\n",
        "with open('medical_qa_robust.py', 'w') as f:\n",
        "    f.write(script_content)\n",
        "\n",
        "print(\"Created medical_qa_robust.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xNGYaLHuQdg",
        "outputId": "acd24cd5-627d-4460-bfea-693288662b80"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created medical_qa_robust.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python medical_qa_robust.py \\\n",
        "    --model_name_or_path \"microsoft/DialoGPT-medium\" \\\n",
        "    --num_epochs 1 \\\n",
        "    --batch_size 1 \\\n",
        "    --gradient_accumulation_steps 4 \\\n",
        "    --max_seq_length 256 \\\n",
        "    --lora_rank 4 \\\n",
        "    --lora_alpha 8 \\\n",
        "    --stage \"1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFs4WmX5swlp",
        "outputId": "cbc41459-631a-4697-fa29-7010a4f65012"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "2025-09-25 05:25:21.969027: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758777921.990866    7270 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758777921.997421    7270 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758777922.014228    7270 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758777922.014274    7270 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758777922.014278    7270 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758777922.014282    7270 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "------------------------------------------------------------\n",
            "Medical QA Fine-Tuning.\n",
            "------------------------------------------------------------\n",
            "Model: microsoft/DialoGPT-medium\n",
            "Stage: 1\n",
            "Batch size: 1\n",
            "Max sequence length: 256\n",
            "LoRA rank: 4\n",
            "============================================================\n",
            "Using target modules: ['c_attn']\n",
            "Loading model: microsoft/DialoGPT-medium\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Tokenizer loaded.\n",
            "Set pad token.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "Base model loaded on CPU.\n",
            "Model to GPU.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/model.py:347: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n",
            "trainable params: 393,216 || all params: 355,216,384 || trainable%: 0.1106975966513977\n",
            "LoRA applied.\n",
            "\n",
            "==================================================\n",
            "STAGE 1: PUBMEDQA\n",
            "==================================================\n",
            "\n",
            " Starting training stage: pubmedqa\n",
            " Data path: pubmedqa_train.jsonl\n",
            " Output directory: ./checkpoints/pubmedqa\n",
            "INFO:__main__:Loaded 1000 examples from pubmedqa_train.jsonl\n",
            "Tokenizing dataset: 100% 1000/1000 [00:01<00:00, 639.39 examples/s]\n",
            " Dataset loaded with 1000 examples.\n",
            " Sample input_ids shape: 1\n",
            " Sample labels shape: 1\n",
            "Training.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/offline-run-20250925_052537-5qbutnhn\u001b[0m\n",
            "  0% 0/50 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "{'loss': 8.8483, 'learning_rate': 4.9e-05, 'epoch': 0.0}\n",
            "  2% 1/50 [00:01<00:51,  1.04s/it]  Fixing input_ids shape: torch.Size([1, 1, 194])\n",
            "  Fixing labels shape: torch.Size([1, 1, 194])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  4% 2/50 [00:01<00:30,  1.59it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  6% 3/50 [00:01<00:22,  2.05it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  8% 4/50 [00:02<00:19,  2.40it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "{'loss': 8.6201, 'learning_rate': 4.5e-05, 'epoch': 0.02}\n",
            " 10% 5/50 [00:02<00:17,  2.63it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 12% 6/50 [00:02<00:15,  2.80it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 14% 7/50 [00:02<00:14,  2.92it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 16% 8/50 [00:03<00:13,  3.00it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 18% 9/50 [00:03<00:13,  3.06it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "{'loss': 8.7862, 'learning_rate': 4e-05, 'epoch': 0.04}\n",
            " 20% 10/50 [00:03<00:12,  3.09it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 22% 11/50 [00:04<00:12,  3.11it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 24% 12/50 [00:04<00:12,  3.11it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 26% 13/50 [00:04<00:11,  3.14it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 28% 14/50 [00:05<00:11,  3.16it/s]  Fixing input_ids shape: torch.Size([1, 1, 239])\n",
            "  Fixing labels shape: torch.Size([1, 1, 239])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "{'loss': 8.8819, 'learning_rate': 3.5e-05, 'epoch': 0.06}\n",
            " 30% 15/50 [00:05<00:11,  3.16it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 32% 16/50 [00:05<00:10,  3.16it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 34% 17/50 [00:06<00:10,  3.18it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 36% 18/50 [00:06<00:10,  3.19it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 38% 19/50 [00:06<00:09,  3.20it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "{'loss': 8.7798, 'learning_rate': 3e-05, 'epoch': 0.08}\n",
            " 40% 20/50 [00:07<00:09,  3.22it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 42% 21/50 [00:07<00:09,  3.20it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 44% 22/50 [00:07<00:08,  3.20it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 46% 23/50 [00:07<00:08,  3.21it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 48% 24/50 [00:08<00:08,  3.22it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "{'loss': 8.7831, 'learning_rate': 2.5e-05, 'epoch': 0.1}\n",
            " 50% 25/50 [00:08<00:07,  3.20it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 52% 26/50 [00:08<00:07,  3.17it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 54% 27/50 [00:09<00:07,  3.17it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 56% 28/50 [00:09<00:06,  3.16it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 58% 29/50 [00:09<00:06,  3.16it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "{'loss': 8.6612, 'learning_rate': 2e-05, 'epoch': 0.12}\n",
            " 60% 30/50 [00:10<00:06,  3.12it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 62% 31/50 [00:10<00:06,  3.07it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 64% 32/50 [00:10<00:05,  3.10it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 66% 33/50 [00:11<00:05,  3.12it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 68% 34/50 [00:11<00:05,  3.12it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "{'loss': 8.5675, 'learning_rate': 1.5e-05, 'epoch': 0.14}\n",
            " 70% 35/50 [00:11<00:04,  3.15it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 72% 36/50 [00:12<00:04,  3.16it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 74% 37/50 [00:12<00:04,  3.17it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 76% 38/50 [00:12<00:03,  3.17it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 78% 39/50 [00:13<00:03,  3.17it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "{'loss': 8.6391, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
            " 80% 40/50 [00:13<00:03,  3.17it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 82% 41/50 [00:13<00:02,  3.16it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 84% 42/50 [00:13<00:02,  3.18it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 86% 43/50 [00:14<00:02,  3.18it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 88% 44/50 [00:14<00:01,  3.18it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "{'loss': 8.3786, 'learning_rate': 5e-06, 'epoch': 0.18}\n",
            " 90% 45/50 [00:14<00:01,  3.19it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 92% 46/50 [00:15<00:01,  3.19it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 94% 47/50 [00:15<00:00,  3.15it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 96% 48/50 [00:15<00:00,  3.16it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            " 98% 49/50 [00:16<00:00,  3.16it/s]  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 256])\n",
            "  Fixing labels shape: torch.Size([1, 1, 256])\n",
            "{'loss': 8.7062, 'learning_rate': 0.0, 'epoch': 0.2}\n",
            "{'train_runtime': 22.4252, 'train_samples_per_second': 8.919, 'train_steps_per_second': 2.23, 'train_loss': 8.68493869781494, 'epoch': 0.2}\n",
            "100% 50/50 [00:16<00:00,  3.03it/s]\n",
            "Training done.\n",
            " Model saved to ./checkpoints/pubmedqa\n",
            " Stage 1 (pubmedqa) completed!\n",
            "\n",
            " Training done.\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20250925_052537-5qbutnhn\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250925_052537-5qbutnhn/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python medical_qa_robust.py \\\n",
        "    --model_name_or_path \"NousResearch/Llama-2-7b-chat-hf\" \\\n",
        "    --num_epochs 1 \\\n",
        "    --batch_size 1 \\\n",
        "    --gradient_accumulation_steps 4 \\\n",
        "    --max_seq_length 128 \\\n",
        "    --lora_rank 4 \\\n",
        "    --lora_alpha 8 \\\n",
        "    --stage \"1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y2cuYEhtu_W",
        "outputId": "547db27f-a6ac-47ba-a569-fc1b38c54fa2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "2025-09-25 05:27:00.043761: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758778020.066639    7785 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758778020.073530    7785 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758778020.091104    7785 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758778020.091148    7785 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758778020.091152    7785 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758778020.091154    7785 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "------------------------------------------------------------\n",
            "Medical QA Fine-Tuning.\n",
            "------------------------------------------------------------\n",
            "Model: NousResearch/Llama-2-7b-chat-hf\n",
            "Stage: 1\n",
            "Batch size: 1\n",
            "Max sequence length: 128\n",
            "LoRA rank: 4\n",
            "============================================================\n",
            "Using target modules: ['q_proj', 'v_proj']\n",
            "Loading model: NousResearch/Llama-2-7b-chat-hf\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Tokenizer loaded.\n",
            "Loading checkpoint shards: 100% 2/2 [00:05<00:00,  2.78s/it]\n",
            "Base model loaded on CPU.\n",
            "Model to GPU.\n",
            "trainable params: 2,097,152 || all params: 6,740,512,768 || trainable%: 0.03111264783824826\n",
            "LoRA applied.\n",
            "\n",
            "==================================================\n",
            "STAGE 1: PUBMEDQA\n",
            "==================================================\n",
            "\n",
            " Starting training stage: pubmedqa\n",
            " Data path: pubmedqa_train.jsonl\n",
            " Output directory: ./checkpoints/pubmedqa\n",
            "INFO:__main__:Loaded 1000 examples from pubmedqa_train.jsonl\n",
            "Tokenizing dataset: 100% 1000/1000 [00:01<00:00, 575.84 examples/s]\n",
            " Dataset loaded with 1000 examples.\n",
            " Sample input_ids shape: 1\n",
            " Sample labels shape: 1\n",
            "Training.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/offline-run-20250925_052724-fij7b5sw\u001b[0m\n",
            "  0% 0/50 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "{'loss': 2.378, 'learning_rate': 4.9e-05, 'epoch': 0.0}\n",
            "  2% 1/50 [00:01<01:12,  1.49s/it]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  4% 2/50 [00:02<00:56,  1.18s/it]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  6% 3/50 [00:03<00:50,  1.08s/it]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  8% 4/50 [00:04<00:47,  1.03s/it]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "{'loss': 2.5337, 'learning_rate': 4.5e-05, 'epoch': 0.02}\n",
            " 10% 5/50 [00:05<00:45,  1.00s/it]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 12% 6/50 [00:06<00:43,  1.01it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 14% 7/50 [00:07<00:42,  1.02it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 16% 8/50 [00:08<00:40,  1.03it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 18% 9/50 [00:09<00:39,  1.03it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "{'loss': 2.3975, 'learning_rate': 4e-05, 'epoch': 0.04}\n",
            " 20% 10/50 [00:10<00:38,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 22% 11/50 [00:11<00:37,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 24% 12/50 [00:12<00:36,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 26% 13/50 [00:12<00:35,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 28% 14/50 [00:13<00:34,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "{'loss': 2.4923, 'learning_rate': 3.5e-05, 'epoch': 0.06}\n",
            " 30% 15/50 [00:14<00:33,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 32% 16/50 [00:15<00:32,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 34% 17/50 [00:16<00:31,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 36% 18/50 [00:17<00:30,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 38% 19/50 [00:18<00:29,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "{'loss': 2.2742, 'learning_rate': 3e-05, 'epoch': 0.08}\n",
            " 40% 20/50 [00:19<00:28,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 42% 21/50 [00:20<00:27,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 44% 22/50 [00:21<00:26,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 46% 23/50 [00:22<00:25,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 48% 24/50 [00:23<00:24,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "{'loss': 2.2097, 'learning_rate': 2.5e-05, 'epoch': 0.1}\n",
            " 50% 25/50 [00:24<00:23,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 52% 26/50 [00:25<00:23,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 54% 27/50 [00:26<00:22,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 56% 28/50 [00:27<00:21,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 58% 29/50 [00:28<00:20,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "{'loss': 2.1421, 'learning_rate': 2e-05, 'epoch': 0.12}\n",
            " 60% 30/50 [00:29<00:19,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 62% 31/50 [00:30<00:18,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 64% 32/50 [00:31<00:17,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 66% 33/50 [00:32<00:16,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 68% 34/50 [00:33<00:15,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "{'loss': 2.1781, 'learning_rate': 1.5e-05, 'epoch': 0.14}\n",
            " 70% 35/50 [00:34<00:14,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 72% 36/50 [00:35<00:13,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 74% 37/50 [00:35<00:12,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 76% 38/50 [00:36<00:11,  1.05it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 78% 39/50 [00:37<00:10,  1.05it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "{'loss': 2.1479, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
            " 80% 40/50 [00:38<00:09,  1.05it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 82% 41/50 [00:39<00:08,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 84% 42/50 [00:40<00:07,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 86% 43/50 [00:41<00:06,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 88% 44/50 [00:42<00:05,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "{'loss': 1.9529, 'learning_rate': 5e-06, 'epoch': 0.18}\n",
            " 90% 45/50 [00:43<00:04,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 92% 46/50 [00:44<00:03,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 94% 47/50 [00:45<00:02,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 96% 48/50 [00:46<00:01,  1.04it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            " 98% 49/50 [00:47<00:00,  1.05it/s]  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "  Fixing input_ids shape: torch.Size([1, 1, 128])\n",
            "  Fixing labels shape: torch.Size([1, 1, 128])\n",
            "{'loss': 2.2144, 'learning_rate': 0.0, 'epoch': 0.2}\n",
            "{'train_runtime': 52.7896, 'train_samples_per_second': 3.789, 'train_steps_per_second': 0.947, 'train_loss': 2.2511671686172487, 'epoch': 0.2}\n",
            "100% 50/50 [00:48<00:00,  1.03it/s]\n",
            "Training done.\n",
            " Model saved to ./checkpoints/pubmedqa\n",
            " Stage 1 (pubmedqa) completed!\n",
            "\n",
            " Training done.\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20250925_052724-fij7b5sw\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250925_052724-fij7b5sw/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "# Loading the fine-tuned model.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./checkpoints/pubmedqa\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\n",
        "model = PeftModel.from_pretrained(base_model, \"./checkpoints/pubmedqa\")\n",
        "\n",
        "\n",
        "prompt = \"Question: What is the normal body temperature? Answer:\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs, max_new_tokens=50)\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337,
          "referenced_widgets": [
            "f577442da1cf447bb8a4292ce0994c0b",
            "08a121c39a9947b58639654d1f803af6",
            "74e1b1e79de240e3a5ddca74e1f25ddd",
            "ca88690472434907bdee0d038db65466",
            "6c2e971b2f11443db3701bc44174461e",
            "15e543c5dec64838a3452a1667854b99",
            "b7feedea3f5047d392aa68643afe4ab4",
            "a3bbff1377864c94a025dcb6f7978381",
            "83a953d696304ab08a9f5d5c3295034d",
            "33053f994f6d4e2191e85d18bc3cb0ee",
            "c478c9d3bb574d97a85f872da9c4690f"
          ]
        },
        "id": "VL28CulTu0Bj",
        "outputId": "e803c4af-055f-46bc-bc09-953f268d1df6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f577442da1cf447bb8a4292ce0994c0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the normal body temperature? Answer: Normal body temperature varies from person to person, but it is generally around 98.6 degrees Fahrenheit (37 degrees Celsius). However, body temperature can fluctuate depending on various factors such as age, sex,\n"
          ]
        }
      ]
    }
  ]
}